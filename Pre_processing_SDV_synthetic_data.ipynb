{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BEbKTFtP3v18wXKs6jaHfqPq5YNY99kL",
      "authorship_tag": "ABX9TyOdiTaGWpjisMNJtVpnaLlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arcursino/tcc_mba/blob/main/Pre_processing_SDV_synthetic_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "VxicLeD8XIHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 150"
      ],
      "metadata": {
        "id": "2I8Lcx8HT1DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "  print(f'User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')"
      ],
      "metadata": {
        "id": "r6bg822QXQ9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Filtrado_Tryout.csv')\n",
        "df = df[(df['TIS'].isin(['Current Production', '2', '3', '1', '0', '-1']))]"
      ],
      "metadata": {
        "id": "7kP2ObaKLtW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['vin',\n",
        " 'TSTAMP',\n",
        " 'cell_id',\n",
        " 'Vehicle_Type',\n",
        " 'TRIM_SERIES',\n",
        " 'Warranty',\n",
        " 'Front_Cross_Camber_Final_Value',\n",
        " 'L_F_Camber',\n",
        " 'CAMBER_FL_INITIAL',\n",
        " 'R_F_Camber',\n",
        " 'CAMBER_FR_INITIAL',\n",
        " 'Rear_Cross_Camber',\n",
        " 'L_R_Camber',\n",
        " 'CAMBER_RL_INITIAL',\n",
        " 'R_R_Camber',\n",
        " 'CAMBER_RR_INITIAL',\n",
        " 'Rear_Thrust_Angle_Final_Value',\n",
        " 'RIDE_HEIGHT_FA_DIFF',\n",
        " 'RIDE_HEIGHT_FL',\n",
        " 'RIDE_HEIGHT_FL_INITIAL',\n",
        " 'RIDE_HEIGHT_FR',\n",
        " 'RIDE_HEIGHT_RA_DIFF',\n",
        " 'RIDE_HEIGHT_RL',\n",
        " 'RIDE_HEIGHT_RR',\n",
        " 'Steering_Wheel_Angle_Final_Value',\n",
        " 'Steering_Wheel_Angle_Preset_Value',\n",
        " 'Front_Sum_Toe_Final_Value',\n",
        " 'TOE_FA_TOTAL_INITIAL',\n",
        " 'L_F_Toe',\n",
        " 'TOE_FL_INITIAL',\n",
        " 'R_F_Toe',\n",
        " 'TOE_FR_INITIAL',\n",
        " 'TOE_RA_TOTAL',\n",
        " 'TOE_RA_TOTAL_INITIAL',\n",
        " 'L_R_Toe',\n",
        " 'TOE_RL_INITIAL',\n",
        " 'R_R_Toe',\n",
        " 'TOE_RR_INITIAL',\n",
        " 'WHEELCENTER_FL',\n",
        " 'WHEELCENTER_FR',\n",
        " 'WHEELCENTER_RL',\n",
        " 'WHEELCENTER_RR',\n",
        " 'Drive_',\n",
        " 'Vehicle_',\n",
        " 'Engine_',\n",
        " 'Cab_',\n",
        " 'CabStyle',\n",
        " 'Engine',\n",
        " 'RearWheels',\n",
        " 'SteeringGear',\n",
        " 'Suspension',\n",
        " 'Tire',\n",
        " 'Transmission',\n",
        " 'Trim_Series_broadcast',\n",
        " 'Wheel',\n",
        " 'wheelbase_broadcast',\n",
        " 'LaneDeparture',\n",
        " 'MY',\n",
        "  'TIS'\n",
        " ]]"
      ],
      "metadata": {
        "id": "pj-ebsOXMI0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_categorical_labels_auto(df, unique_threshold=50, exclude_cols=None):\n",
        "    \"\"\"\n",
        "    Automatically identifies potential categorical columns based on dtype and\n",
        "    unique value count, and transforms their labels into the format\n",
        "    'columnname_index'.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        unique_threshold (int): Maximum number of unique values for a column\n",
        "                                to be considered categorical. Columns with more\n",
        "                                unique values than this are likely not\n",
        "                                simple categories (e.g., IDs, free text).\n",
        "                                Defaults to 50.\n",
        "        exclude_cols (list, optional): A list of column names to explicitly\n",
        "                                     exclude from the automatic transformation,\n",
        "                                     even if they meet the criteria.\n",
        "                                     Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with transformed categorical labels.\n",
        "    \"\"\"\n",
        "    df_transformed = df.copy() # Work on a copy to not modify the original DataFrame\n",
        "\n",
        "    exclude_cols = ['TSTAMP', 'TIS']\n",
        "\n",
        "    if exclude_cols is None:\n",
        "        exclude_cols = []\n",
        "\n",
        "    print(\"--- Starting Automatic Label Transformation ---\")\n",
        "\n",
        "    # 1. Identify potential categorical columns\n",
        "    # We look for object (strings) and category dtypes\n",
        "    potential_cols = df_transformed.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # Filter these columns:\n",
        "    # - Exclude columns explicitly listed in exclude_cols\n",
        "    # - Exclude columns where the number of unique values is above the threshold\n",
        "    #   (as these are less likely to be simple categories)\n",
        "    categorical_cols_to_transform = [\n",
        "        col for col in potential_cols\n",
        "        if col not in exclude_cols #and df_transformed[col].nunique() <= unique_threshold\n",
        "    ]\n",
        "\n",
        "    print(f\"Identified {len(categorical_cols_to_transform)} potential categorical columns based on criteria (unique <= {unique_threshold}, excluding {exclude_cols}): {categorical_cols_to_transform}\")\n",
        "\n",
        "    # 2. Transform labels for each identified column\n",
        "    for col in categorical_cols_to_transform:\n",
        "        # Ensure the column is category dtype temporarily to get categories/codes\n",
        "        # .astype('category') is safe even if it's already category\n",
        "        # .cat accessor gives us access to categorical properties\n",
        "        try:\n",
        "            cat_col = df_transformed[col].astype('category')\n",
        "\n",
        "            # Get the unique categories in the order they are assigned codes (0, 1, 2...)\n",
        "            # .cat.categories property gives the unique values excluding NaN\n",
        "            original_categories = cat_col.cat.categories\n",
        "\n",
        "            # Create the mapping dictionary: {original_value: 'columnname_code'}\n",
        "            # The index 'i' corresponds to the 0-based code assigned by pandas\n",
        "            mapping = {\n",
        "                original_categories[i]: f\"{col}_{i}\"\n",
        "                for i in range(len(original_categories))\n",
        "            }\n",
        "\n",
        "            # Apply the mapping to the column\n",
        "            # .map() is suitable here; it applies the mapping and handles NaN correctly\n",
        "            df_transformed[col] = df_transformed[col].map(mapping)\n",
        "\n",
        "            #print(f\"  Transformed column '{col}'. Mapping used: {mapping}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle potential errors during transformation for a specific column\n",
        "            print(f\"  Could not transform column '{col}' due to error: {e}\")\n",
        "            # Optionally, you could remove this column or leave it as is\n",
        "\n",
        "\n",
        "    print(\"--- Automatic Label Transformation Complete ---\")\n",
        "    return df_transformed\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "# We'll use a threshold of 10 for this small example dataset\n",
        "# We might want to exclude 'ID' even though it's numerical, or 'Description'\n",
        "# because it has too many unique values and isn't truly categorical.\n",
        "# The function's logic automatically excludes 'Weight_kg' (float) and 'Is_Fragile' (bool)\n",
        "# and 'Description' (unique > 10).\n",
        "# It will identify 'Color', 'Size', 'City', 'Material', 'Rating'.\n",
        "# Let's explicitly exclude 'Rating' just to show how exclude_cols works.\n",
        "df_new = transform_categorical_labels_auto(df, unique_threshold=10, exclude_cols=['Rating'])\n",
        "\n"
      ],
      "metadata": {
        "id": "9lAe0KguNUyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.TSTAMP.unique()"
      ],
      "metadata": {
        "id": "vGArz08cNYR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.api.types import is_numeric_dtype, is_object_dtype, is_categorical_dtype\n",
        "\n",
        "def clean_warranty_df(df):\n",
        "    # 1. Drop columns where more than 80% are null\n",
        "    thresh = len(df) * 0.2  # minimum non-null count to keep column\n",
        "    df = df.dropna(axis=1, thresh=thresh)\n",
        "\n",
        "    # Columns excluding 'Warranty' to fill or drop nulls\n",
        "    cols = df.columns.drop('Warranty')\n",
        "\n",
        "    # 2. For Warranty_1 rows, fill null with median or mode\n",
        "    for col in cols:\n",
        "        if df[col].isnull().any():\n",
        "            if is_numeric_dtype(df[col]):\n",
        "                median_val = df[col].median()\n",
        "                df[col].fillna(median_val, inplace=True)\n",
        "            else:\n",
        "                mode_val = df[col].mode()\n",
        "                if not mode_val.empty:\n",
        "                    df[col].fillna(mode_val[0], inplace=True)\n",
        "                else:\n",
        "                    # If no mode found, just fill with a placeholder or leave as is\n",
        "                    df[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "    cleaned_df = df.copy()\n",
        "\n",
        "    # Optional: sort index if desired to maintain original order\n",
        "    cleaned_df = cleaned_df.sort_index()\n",
        "\n",
        "    return cleaned_df"
      ],
      "metadata": {
        "id": "7dCbfzhD-6Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df = clean_warranty_df(df_new.copy())"
      ],
      "metadata": {
        "id": "ilN1-kli-9yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Instalar a biblioteca SDV (se ainda não tiver instalada)\n",
        " !pip install sdv\n"
      ],
      "metadata": {
        "id": "9VDiAXCycdY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sdv.metadata import Metadata\n",
        "\n",
        "metadata = Metadata.detect_from_dataframe(\n",
        "    data=processed_df,\n",
        "    table_name='Alignment')"
      ],
      "metadata": {
        "id": "TGQ7kwxcecsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.visualize()"
      ],
      "metadata": {
        "id": "_w11TXNWelpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''metadata.update_column(\n",
        "    column_name='TSTAMP',\n",
        "    sdtype='datetime',\n",
        "    datetime_format='%Y-%m-%d')'''"
      ],
      "metadata": {
        "id": "nrMqmYSVe8jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.validate()"
      ],
      "metadata": {
        "id": "9pDuzf52fUh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.save_to_json(filepath='my_metadata_v1.json')"
      ],
      "metadata": {
        "id": "d_rz4Gcdfk0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = Metadata.load_from_json(filepath='my_metadata_v1.json')"
      ],
      "metadata": {
        "id": "e2qY5176foqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata"
      ],
      "metadata": {
        "id": "zLYcRh4Cfq9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display columns with missing values and their count\n",
        "print(\"Columns with missing values before filling:\")\n",
        "print(processed_df.isnull().sum()[processed_df.isnull().sum() > 0])\n",
        "\n",
        "# Identify numerical columns\n",
        "numerical_cols = processed_df.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Identify object (transformed categorical) columns\n",
        "object_cols = processed_df.select_dtypes(include='object').columns\n",
        "\n",
        "# Fill missing values in numerical columns with the mean\n",
        "print(\"\\nFilling missing numerical values with mean...\")\n",
        "for col in numerical_cols:\n",
        "    if processed_df[col].isnull().any():\n",
        "        mean_value = processed_df[col].mean()\n",
        "        processed_df[col].fillna(mean_value, inplace=True)\n",
        "        print(f\"  Filled NaN in '{col}' with mean: {mean_value:.2f}\")\n",
        "\n",
        "# Fill missing values in object columns with the mode\n",
        "print(\"\\nFilling missing object (transformed categorical) values with mode...\")\n",
        "for col in object_cols:\n",
        "    if processed_df[col].isnull().any():\n",
        "        # .mode()[0] gets the first mode if there are multiple\n",
        "        mode_value = processed_df[col].mode()[0]\n",
        "        processed_df[col].fillna(mode_value, inplace=True)\n",
        "        print(f\"  Filled NaN in '{col}' with mode: '{mode_value}'\")\n",
        "\n",
        "# Verify that there are no more missing values\n",
        "print(\"\\nColumns with missing values after filling:\")\n",
        "print(processed_df.isnull().sum()[processed_df.isnull().sum() > 0])\n",
        "\n"
      ],
      "metadata": {
        "id": "vupvzIgbVxwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.isnull().sum()"
      ],
      "metadata": {
        "id": "cJJXAm8vWkOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sdv.single_table import GaussianCopulaSynthesizer\n",
        "\n",
        "# Step 1: Create the synthesizer\n",
        "synthesizer = GaussianCopulaSynthesizer(metadata)\n",
        "\n",
        "# Step 2: Train the synthesizer\n",
        "synthesizer.fit(processed_df)\n",
        "\n",
        "# Step 3: Generate synthetic data\n",
        "synthetic_data = synthesizer.sample(num_rows=10000)"
      ],
      "metadata": {
        "id": "fHoaGDEKf3WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data.to_csv('/content/drive/MyDrive/TCC_MBA/alignment_synthetic_data.csv', index=False)"
      ],
      "metadata": {
        "id": "Q0UFOD32JPwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_1 = metadata.to_dict()"
      ],
      "metadata": {
        "id": "ad-TQYHLw68g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sdv.evaluation.single_table import run_diagnostic, evaluate_quality\n",
        "from sdv.evaluation.single_table import get_column_plot\n",
        "\n",
        "# 1. perform basic validity checks\n",
        "diagnostic = run_diagnostic(processed_df, synthetic_data, metadata)\n",
        "\n",
        "# 2. measure the statistical similarity\n",
        "quality_report = evaluate_quality(processed_df, synthetic_data, metadata)\n",
        "\n"
      ],
      "metadata": {
        "id": "4vlN_wQbDNPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic.get_score()"
      ],
      "metadata": {
        "id": "ljvWUtBixijI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_report.get_score()"
      ],
      "metadata": {
        "id": "Mw6evzR6xrqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_report.get_properties()"
      ],
      "metadata": {
        "id": "W_wkwkxBxyLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic.get_properties()"
      ],
      "metadata": {
        "id": "qVMmPRPhx2WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pio.renderers.default = 'colab'"
      ],
      "metadata": {
        "id": "LOgvyschMCWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=quality_report.get_visualization(property_name='Column Shapes')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "652Bm1qWydz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=quality_report.get_visualization(property_name='Column Pair Trends')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gBUiPubpzqVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the properties from the quality_report report\n",
        "properties = quality_report.get_properties()\n",
        "\n",
        "# Iterate through properties and get visualization if available\n",
        "print(\"Attempting to show visualizations for properties:\")\n",
        "for prop in properties['Property'].unique():\n",
        "    try:\n",
        "        print(f\"- Showing visualization for property: {prop}\")\n",
        "        fig = quality_report.get_visualization(property_name=prop)\n",
        "        fig.show()\n",
        "    except TypeError as e:\n",
        "        # Catch the TypeError if a property name doesn't have a visualization\n",
        "        print(f\"  Could not get visualization for '{prop}'. Error: {e}\")\n",
        "    except Exception as e:\n",
        "        # Catch any other potential errors during visualization retrieval\n",
        "        print(f\"  An error occurred while getting visualization for '{prop}': {e}\")"
      ],
      "metadata": {
        "id": "Fm1YJLpYae8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the properties from the diagnostic report\n",
        "properties = diagnostic.get_properties()\n",
        "\n",
        "# Iterate through properties and get visualization if available\n",
        "print(\"Attempting to show visualizations for properties:\")\n",
        "for prop in properties['Property'].unique():\n",
        "    try:\n",
        "        print(f\"- Showing visualization for property: {prop}\")\n",
        "        fig = diagnostic.get_visualization(property_name=prop)\n",
        "        fig.show()\n",
        "    except TypeError as e:\n",
        "        # Catch the TypeError if a property name doesn't have a visualization\n",
        "        print(f\"  Could not get visualization for '{prop}'. Error: {e}\")\n",
        "    except Exception as e:\n",
        "        # Catch any other potential errors during visualization retrieval\n",
        "        print(f\"  An error occurred while getting visualization for '{prop}': {e}\")"
      ],
      "metadata": {
        "id": "gp2_LHCAnIy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "properties"
      ],
      "metadata": {
        "id": "MwPwbeEOkvTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMQc8rpE9YQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# --- Passo 3: Gerar e Salvar o Relatório Visual (HTML) ---\n",
        "output_html_file = \"relatorio_qualidade_sdv.html\"\n",
        "\n",
        "print(f\"\\nGerando e salvando o relatório visual em '{output_html_file}'...\")\n",
        "\n",
        "# Chame .get_visualization() e depois use .write_html() para salvar como arquivo HTML\n",
        "fig = quality_report.get_visualization(property_name='Column Pair Trends')\n",
        "fig.write_html(output_html_file) # Use write_html instead of to_file\n",
        "\n",
        "# --- Confirmação ---\n",
        "if os.path.exists(output_html_file):\n",
        "    print(f\"\\nRelatório HTML gerado com sucesso! Abra o arquivo '{output_html_file}' no seu navegador para ver os detalhes.\")\n",
        "else:\n",
        "    print(\"\\nHouve um problema ao gerar o relatório HTML.\")"
      ],
      "metadata": {
        "id": "fDg7EgPyn7qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#synthetic_data = pd.read_csv('/content/alignment_synthetic_data (1).csv')"
      ],
      "metadata": {
        "id": "iAg2ks139ay_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6MRArzueEo15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# --- Passo 1: Selecionar Apenas Colunas Numéricas ---\n",
        "# As correlações de Pearson/Spearman são tipicamente calculadas para dados numéricos.\n",
        "# Vamos garantir que estamos trabalhando apenas com esses tipos de colunas.\n",
        "\n",
        "# Identificar colunas numéricas em ambos os DataFrames para garantir consistência\n",
        "# Usaremos as colunas numéricas do DataFrame real como referência,\n",
        "# assumindo que o DataFrame sintético possui as mesmas colunas numéricas.\n",
        "numerical_cols_real = processed_df.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Filtrar ambos os DataFrames para incluir apenas as colunas numéricas\n",
        "processed_df_numerical = processed_df[numerical_cols_real]\n",
        "synthetic_data_numerical = synthetic_data[numerical_cols_real]\n",
        "\n",
        "print(f\"Comparando correlações para {len(numerical_cols_real)} colunas numéricas.\")\n",
        "print(\"Colunas numéricas:\", list(numerical_cols_real))\n",
        "\n",
        "# --- Passo 2: Calcular as Matrizes de Correlação ---\n",
        "\n",
        "# Matriz de Correlação dos Dados Reais\n",
        "correlation_matrix_real = processed_df_numerical.corr()\n",
        "\n",
        "# Matriz de Correlação dos Dados Sintéticos\n",
        "correlation_matrix_synthetic = synthetic_data_numerical.corr()\n",
        "\n",
        "# --- Passo 3: Visualizar as Matrizes de Correlação Lado a Lado usando Heatmaps ---\n",
        "\n",
        "# Definir o tamanho da figura. Ajuste conforme a quantidade de colunas.\n",
        "# Uma figura mais larga é útil para colocar dois heatmaps lado a lado.\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8)) # 1 linha, 2 colunas\n",
        "\n",
        "# Heatmap para os Dados Reais\n",
        "# Removemos 'cbar_kw' daqui\n",
        "sns.heatmap(\n",
        "    correlation_matrix_real,\n",
        "    ax=axes[0],          # Especifica em qual subplot desenhar\n",
        "    annot=False,         # Defina como True para mostrar valores (pode poluir)\n",
        "    cmap='coolwarm',     # Esquema de cores\n",
        "    vmin=-1, vmax=1,     # Garante que as escalas de cor sejam comparáveis (-1 a 1)\n",
        "    square=True,         # Faz os \"quadradinhos\" serem quadrados\n",
        "    # cbar_kw={'label': 'Coeficiente de Correlação'} # REMOVIDO\n",
        ")\n",
        "axes[0].set_title('Matriz de Correlação (Dados Reais)', fontsize=14)\n",
        "axes[0].tick_params(axis='x', rotation=90) # Rotaciona os rótulos do eixo X\n",
        "axes[0].tick_params(axis='y', rotation=0)  # Garante que os rótulos do eixo Y não girem\n",
        "\n",
        "# Heatmap para os Dados Sintéticos\n",
        "# Removemos 'cbar_kw' daqui\n",
        "sns.heatmap(\n",
        "    correlation_matrix_synthetic,\n",
        "    ax=axes[1],          # Especifica em qual subplot desenhar\n",
        "    annot=False,         # Defina como True para mostrar valores\n",
        "    cmap='coolwarm',     # Esquema de cores\n",
        "    vmin=-1, vmax=1,     # Garante que as escalas de cor sejam comparáveis\n",
        "    square=True,         # Faz os \"quadradinhos\" serem quadrados\n",
        "    # cbar_kw={'label': 'Coeficiente de Correlação'} # REMOVIDO\n",
        ")\n",
        "axes[1].set_title('Matriz de Correlação (Dados Sintéticos)', fontsize=14)\n",
        "axes[1].tick_params(axis='x', rotation=90) # Rotaciona os rótulos do eixo X\n",
        "axes[1].tick_params(axis='y', rotation=0)  # Garante que os rótulos do eixo Y não girem\n",
        "\n",
        "# Adicionar o label à barra de cor manualmente após a criação do heatmap\n",
        "# seaborn cria a colorbar axis automaticamente\n",
        "# Para o primeiro heatmap:\n",
        "if axes[0].collections: # Check if heatmap was drawn\n",
        "    cbar0 = axes[0].collections[0].colorbar\n",
        "    cbar0.set_label('Coeficiente de Correlação')\n",
        "\n",
        "# Para o segundo heatmap:\n",
        "if axes[1].collections: # Check if heatmap was drawn\n",
        "    cbar1 = axes[1].collections[0].colorbar\n",
        "    cbar1.set_label('Coeficiente de Correlação')\n",
        "\n",
        "\n",
        "# Ajustar o layout para evitar sobreposição de elementos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibir os gráficos\n",
        "plt.show()\n",
        "\n",
        "# --- Opcional: Calcular a Diferença Absoluta entre as Matrizes ---\n",
        "# Isso pode te dar uma ideia quantitativa da \"distância\" entre as correlações.\n",
        "# Use .abs() para obter o valor absoluto das diferenças.\n",
        "correlation_difference = (correlation_matrix_real - correlation_matrix_synthetic).abs()\n",
        "\n",
        "print(\"\\nMatriz de Diferença Absoluta das Correlações:\")\n",
        "# print(correlation_difference) # Descomente para imprimir a matriz de diferenças\n",
        "\n",
        "# Visualizar a matriz de diferenças absolutas\n",
        "plt.figure(figsize=(10, 8))\n",
        "# Removemos 'cbar_kw' daqui também\n",
        "sns.heatmap(\n",
        "    correlation_difference,\n",
        "    annot=False,\n",
        "    cmap='Reds', # Um colormap que destaca valores maiores\n",
        "    vmin=0, vmax=1, # Diferença vai de 0 (sem diferença) a 1 (correlação oposta)\n",
        "    square=True,\n",
        "    # cbar_kw={'label': 'Diferença Absoluta no Coeficiente de Correlação'} # REMOVIDO\n",
        ")\n",
        "plt.title('Diferença Absoluta nas Matrizes de Correlação (Real vs Sintético)', fontsize=16)\n",
        "plt.tick_params(axis='x', rotation=90)\n",
        "plt.tick_params(axis='y', rotation=0)\n",
        "\n",
        "# Adicionar o label à barra de cor para o heatmap de diferença\n",
        "# Get the current axes and find the colorbar\n",
        "cbar_diff = plt.gca().collections[0].colorbar\n",
        "cbar_diff.set_label('Diferença Absoluta no Coeficiente de Correlação')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VsnNS8-wqc93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_difference"
      ],
      "metadata": {
        "id": "4myYG8137RfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "V5CJ6sCYw0t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar a relação entre duas colunas específicas (por exemplo, 'L_F_Camber' e 'R_F_Camber')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=processed_df, x='L_F_Toe', y='R_F_Toe', alpha=0.5, label='Real Data')\n",
        "sns.scatterplot(data=synthetic_data, x='L_F_Toe', y='R_F_Toe', alpha=0.5, label='Synthetic Data')\n",
        "plt.title('Comparação da Relação entre Left Front Toe e Right Front Toe')\n",
        "plt.xlabel('L_F_Toe')\n",
        "plt.ylabel('R_F_Toe')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ScUFvz7eqdGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seaborn.pairplot pode ser usado para visualizar pares de colunas selecionadas\n",
        "sns.pairplot(processed_df[['L_F_Toe', 'R_F_Toe', 'Steering_Wheel_Angle_Final_Value']])\n",
        "plt.suptitle('Pair Plot for Selected Toe Columns (Real Data)', y=1.02) # Adiciona título acima\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7zHpSqabqdJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seaborn.pairplot pode ser usado para visualizar pares de colunas selecionadas\n",
        "sns.pairplot(synthetic_data[['L_F_Toe', 'R_F_Toe', 'Steering_Wheel_Angle_Final_Value']])\n",
        "plt.suptitle('Pair Plot for Selected Toe Columns (Synthetic Data)', y=1.02) # Adiciona título acima\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yHvSieBLsO_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5x2VM0Iix15A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Passo 1: Selecionar as colunas de interesse ---\n",
        "# Certifique-se de que as colunas existem em ambos os DataFrames\n",
        "cols_to_plot = ['L_F_Toe', 'R_F_Toe', 'Steering_Wheel_Angle_Final_Value']\n",
        "\n",
        "# Verificar se as colunas existem em ambos os DataFrames antes de prosseguir\n",
        "if not all(col in processed_df.columns for col in cols_to_plot):\n",
        "    print(f\"Erro: Algumas colunas não encontradas no DataFrame real: {[col for col in cols_to_plot if col not in processed_df.columns]}\")\n",
        "elif not all(col in synthetic_data.columns for col in cols_to_plot):\n",
        "     print(f\"Erro: Algumas colunas não encontradas no DataFrame sintético: {[col for col in cols_to_plot if col not in synthetic_data.columns]}\")\n",
        "else:\n",
        "    # --- Passo 2: Preparar os DataFrames para a comparação ---\n",
        "\n",
        "    # Selecionar apenas as colunas relevantes de cada DataFrame\n",
        "    real_subset = processed_df[cols_to_plot].copy()\n",
        "    synthetic_subset = synthetic_data[cols_to_plot].copy()\n",
        "\n",
        "    # Adicionar uma coluna para identificar a origem dos dados\n",
        "    real_subset['Data_Source'] = 'Real'\n",
        "    synthetic_subset['Data_Source'] = 'Synthetic'\n",
        "\n",
        "    # Combinar os dois DataFrames\n",
        "    combined_df = pd.concat([real_subset, synthetic_subset], ignore_index=True)\n",
        "\n",
        "    print(\"DataFrames combinados para pair plot com sucesso.\")\n",
        "\n",
        "    # --- Passo 3: Gerar o Pair Plot Comparativo ---\n",
        "\n",
        "    # Use seaborn.pairplot no DataFrame combinado\n",
        "    # O argumento 'hue' plota pontos com cores diferentes baseadas na coluna 'Data_Source'\n",
        "    # O argumento 'diag_kws' permite personalizar os plots diagonais (geralmente histogramas ou kde)\n",
        "    # O argumento 'plot_kws' permite personalizar os plots fora da diagonal (scatter plots)\n",
        "\n",
        "    # Exemplo de customização: usar KDE nos diagonais e scatter plots com transparência\n",
        "    g = sns.pairplot(\n",
        "        combined_df,\n",
        "        hue='Data_Source',        # Coluna para diferenciar os pontos por cor\n",
        "        vars=cols_to_plot,        # As colunas a serem plotadas\n",
        "        diag_kind='kde',          # Tipo de plot na diagonal (Kernel Density Estimate)\n",
        "        plot_kws={'alpha': 0.6, 's': 10}, # alpha: transparência, s: tamanho do ponto\n",
        "        height=2.5                # Altura de cada subplot\n",
        "    )\n",
        "\n",
        "    # Ajustar o título\n",
        "    g.fig.suptitle('Comparação Pair Plot: Dados Reais vs. Sintéticos', y=1.02, fontsize=16) # Adiciona título acima\n",
        "\n",
        "    # Melhorar a legenda (opcional, pairplot cria uma por padrão)\n",
        "    # g.add_legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # --- Opcional: Pair plot com histograma na diagonal ---\n",
        "    print(\"\\nGerando Pair Plot com Histograma na diagonal...\")\n",
        "    g_hist = sns.pairplot(\n",
        "        combined_df,\n",
        "        hue='Data_Source',\n",
        "        vars=cols_to_plot,\n",
        "        diag_kind='hist',        # Tipo de plot na diagonal (Histograma)\n",
        "        plot_kws={'alpha': 0.6, 's': 10},\n",
        "        height=2.5\n",
        "    )\n",
        "    g_hist.fig.suptitle('Comparação Pair Plot (Hist): Dados Reais vs. Sintéticos', y=1.02, fontsize=16)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ds8m1PwGsqG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seaborn.pairplot pode ser usado para visualizar pares de colunas selecionadas\n",
        "sns.pairplot(processed_df[['RIDE_HEIGHT_FA_DIFF', 'RIDE_HEIGHT_FR', 'RIDE_HEIGHT_FL_INITIAL']])\n",
        "plt.suptitle('Pair Plot for Selected Toe Columns (Real Data)', y=1.02) # Adiciona título acima\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WNVbk-q0x33a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seaborn.pairplot pode ser usado para visualizar pares de colunas selecionadas\n",
        "sns.pairplot(synthetic_data[['RIDE_HEIGHT_FA_DIFF', 'RIDE_HEIGHT_FR', 'RIDE_HEIGHT_FL_INITIAL']])\n",
        "plt.suptitle('Pair Plot for Selected Toe Columns (Synthetic Data)', y=1.02) # Adiciona título acima\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_-NKi7iNx87L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Passo 1: Selecionar as colunas de interesse ---\n",
        "# Certifique-se de que as colunas existem em ambos os DataFrames\n",
        "cols_to_plot = ['RIDE_HEIGHT_FA_DIFF', 'RIDE_HEIGHT_FR', 'RIDE_HEIGHT_FL_INITIAL']\n",
        "\n",
        "# Verificar se as colunas existem em ambos os DataFrames antes de prosseguir\n",
        "if not all(col in processed_df.columns for col in cols_to_plot):\n",
        "    print(f\"Erro: Algumas colunas não encontradas no DataFrame real: {[col for col in cols_to_plot if col not in processed_df.columns]}\")\n",
        "elif not all(col in synthetic_data.columns for col in cols_to_plot):\n",
        "     print(f\"Erro: Algumas colunas não encontradas no DataFrame sintético: {[col for col in cols_to_plot if col not in synthetic_data.columns]}\")\n",
        "else:\n",
        "    # --- Passo 2: Preparar os DataFrames para a comparação ---\n",
        "\n",
        "    # Selecionar apenas as colunas relevantes de cada DataFrame\n",
        "    real_subset = processed_df[cols_to_plot].copy()\n",
        "    synthetic_subset = synthetic_data[cols_to_plot].copy()\n",
        "\n",
        "    # Adicionar uma coluna para identificar a origem dos dados\n",
        "    real_subset['Data_Source'] = 'Real'\n",
        "    synthetic_subset['Data_Source'] = 'Synthetic'\n",
        "\n",
        "    # Combinar os dois DataFrames\n",
        "    combined_df = pd.concat([real_subset, synthetic_subset], ignore_index=True)\n",
        "\n",
        "    print(\"DataFrames combinados para pair plot com sucesso.\")\n",
        "\n",
        "    # --- Passo 3: Gerar o Pair Plot Comparativo ---\n",
        "\n",
        "    # Use seaborn.pairplot no DataFrame combinado\n",
        "    # O argumento 'hue' plota pontos com cores diferentes baseadas na coluna 'Data_Source'\n",
        "    # O argumento 'diag_kws' permite personalizar os plots diagonais (geralmente histogramas ou kde)\n",
        "    # O argumento 'plot_kws' permite personalizar os plots fora da diagonal (scatter plots)\n",
        "\n",
        "    # Exemplo de customização: usar KDE nos diagonais e scatter plots com transparência\n",
        "    g = sns.pairplot(\n",
        "        combined_df,\n",
        "        hue='Data_Source',        # Coluna para diferenciar os pontos por cor\n",
        "        vars=cols_to_plot,        # As colunas a serem plotadas\n",
        "        diag_kind='kde',          # Tipo de plot na diagonal (Kernel Density Estimate)\n",
        "        plot_kws={'alpha': 0.6, 's': 10}, # alpha: transparência, s: tamanho do ponto\n",
        "        height=2.5                # Altura de cada subplot\n",
        "    )\n",
        "\n",
        "    # Ajustar o título\n",
        "    g.fig.suptitle('Comparação Pair Plot: Dados Reais vs. Sintéticos', y=1.02, fontsize=16) # Adiciona título acima\n",
        "\n",
        "    # Melhorar a legenda (opcional, pairplot cria uma por padrão)\n",
        "    # g.add_legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # --- Opcional: Pair plot com histograma na diagonal ---\n",
        "    print(\"\\nGerando Pair Plot com Histograma na diagonal...\")\n",
        "    g_hist = sns.pairplot(\n",
        "        combined_df,\n",
        "        hue='Data_Source',\n",
        "        vars=cols_to_plot,\n",
        "        diag_kind='hist',        # Tipo de plot na diagonal (Histograma)\n",
        "        plot_kws={'alpha': 0.6, 's': 10},\n",
        "        height=2.5\n",
        "    )\n",
        "    g_hist.fig.suptitle('Comparação Pair Plot (Hist): Dados Reais vs. Sintéticos', y=1.02, fontsize=16)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hPWCidBZxE2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Contando as colunas por tipo ---\n",
        "\n",
        "# 1. Contar colunas numéricas:\n",
        "# Usamos np.number para pegar todos os tipos numéricos (int, float, etc.)\n",
        "num_cols = synthetic_data.select_dtypes(include=np.number).columns\n",
        "count_numeric = len(num_cols)\n",
        "\n",
        "# 2. Contar colunas categóricas:\n",
        "# Incluímos 'object' (geralmente strings) e 'category' (tipo categórico explícito do pandas)\n",
        "cat_cols = synthetic_data.select_dtypes(include=['object', 'category']).columns\n",
        "count_categorical = len(cat_cols)\n",
        "\n",
        "# 3. Contar colunas timestamp:\n",
        "# Incluímos 'datetime64' para pegar os tipos de data e hora\n",
        "ts_cols = synthetic_data.select_dtypes(include='datetime64').columns\n",
        "count_timestamp = len(ts_cols)\n",
        "\n",
        "# --- Exibindo os resultados ---\n",
        "print(f\"Total de colunas numéricas: {count_numeric}\")\n",
        "# Opcional: ver quais são: print(f\"Colunas numéricas: {list(num_cols)}\")\n",
        "\n",
        "print(f\"Total de colunas categóricas: {count_categorical}\")\n",
        "# Opcional: ver quais são: print(f\"Colunas categóricas: {list(cat_cols)}\")\n",
        "\n",
        "print(f\"Total de colunas timestamp: {count_timestamp}\")\n",
        "# Opcional: ver quais são: print(f\"Colunas timestamp: {list(ts_cols)}\")\n",
        "\n",
        "# Opcional: Contar outras colunas (que não se encaixam nas categorias acima)\n",
        "count_other = len(synthetic_data.columns) - (count_numeric + count_categorical + count_timestamp)\n",
        "print(f\"Total de outras colunas: {count_other}\")"
      ],
      "metadata": {
        "id": "zotNvz5FfQo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "M39G207fw-6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prince"
      ],
      "metadata": {
        "id": "Z4to5rFb-XH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols_for_mca = [\n",
        "    'Vehicle_Type',\n",
        "    'TRIM_SERIES',\n",
        "    'WHEELBASE',\n",
        "    'Drive_',      # Se essas foram transformadas\n",
        "    'Vehicle_',\n",
        "    'Engine_',\n",
        "    'Cab_',\n",
        "    'CabStyle',\n",
        "    'Engine',\n",
        "    'RearWheels',\n",
        "    'SteeringGear',\n",
        "    'Suspension',\n",
        "    'Tire',\n",
        "    'Transmission',\n",
        "    'Trim_Series_broadcast',\n",
        "    'Wheel',\n",
        "    'wheelbase_broadcast',\n",
        "    'LaneDeparture',\n",
        "    'MY',\n",
        "    'Warranty', # 'Warranty' também é categórica\n",
        "    'TIS'\n",
        "]\n",
        "\n",
        "# Opcional: Filtre para garantir que essas colunas existam no processed_df\n",
        "categorical_cols_for_mca = [col for col in categorical_cols_for_mca if col in processed_df.columns]\n",
        "\n",
        "print(f\"Colunas categóricas selecionadas para MCA: {categorical_cols_for_mca}\")\n",
        "\n",
        "# Crie um sub-DataFrame apenas com as colunas categóricas\n",
        "df_categorical = processed_df[categorical_cols_for_mca].copy()"
      ],
      "metadata": {
        "id": "-qapMn_D-XKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se há NaNs nas colunas categóricas. MCA geralmente não lida com NaNs.\n",
        "# Se houver, você precisará tratá-los (preencher com moda, por exemplo).\n",
        "print(\"\\nVerificando NaNs em colunas categóricas:\")\n",
        "print(df_categorical.isnull().sum())\n",
        "\n",
        "# Se houver NaNs, preencha-os (ex: com a moda)\n",
        "for col in df_categorical.columns:\n",
        "    if df_categorical[col].isnull().any():\n",
        "        mode_val = df_categorical[col].mode()\n",
        "        if not mode_val.empty:\n",
        "            df_categorical[col].fillna(mode_val[0], inplace=True)\n",
        "            print(f\"Preenchendo NaNs em '{col}' com a moda: '{mode_val[0]}'\")\n",
        "        else:\n",
        "            # Trate colunas onde a moda não pôde ser calculada (todos NaNs ou valores únicos)\n",
        "            # Pode ser necessário dropar a coluna ou preencher com um valor placeholder\n",
        "             df_categorical[col].fillna('NaN_Filled', inplace=True)\n",
        "             print(f\"Preenchendo NaNs em '{col}' com 'NaN_Filled' (moda vazia).\")\n"
      ],
      "metadata": {
        "id": "ueKRh-0u-XNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "import statsmodels.api as sm\n",
        "import prince\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'browser'\n",
        "import plotly.graph_objects as go\n",
        "from itertools import combinations\n"
      ],
      "metadata": {
        "id": "jvO-6svf-o8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns to not interfere the algorithm to plot data\n",
        "df_categorical.rename(columns=lambda x: x.replace('_', '.'), inplace=True)"
      ],
      "metadata": {
        "id": "B5dMpLDi_zmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create lists to append columns that's import or not\n",
        "p_value_h1 = []\n",
        "p_value_h0 = []\n",
        "chi2s = dict()\n",
        "\n",
        "# Combine and apply Chi-Square Test into all columns\n",
        "for item in list(combinations(df_categorical.columns, 2)):\n",
        "    #print(item, '\\n')\n",
        "\n",
        "    table = pd.crosstab(df_categorical[item[0]], df_categorical[item[1]])\n",
        "    #print(table)\n",
        "\n",
        "    chi2, pvalue, gl, freq_esp = chi2_contingency(table)\n",
        "    #print(f\"Qui² Statistic: {round(chi2, 2)}\")\n",
        "    #print(f\"p-value: {round(pvalue, 4)}\", \"\\n\")\n",
        "    if 'TIS' in item :\n",
        "        if pvalue < 0.05:\n",
        "            p_value_h1= [item[0] + item[1]]\n",
        "            key_col = ', '.join(p_value_h1)\n",
        "            chi2s[key_col] = chi2\n",
        "\n",
        "    else:\n",
        "        p_value_h0.append(item[0])\n",
        "        p_value_h0.append(item[1])\n",
        "        p_value_h0.append('\\n')"
      ],
      "metadata": {
        "id": "awBdG70J-o-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_categorical.columns"
      ],
      "metadata": {
        "id": "rZAcvy2VAa6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print all possible combination that accept H1 and Reject H0\n",
        "print(f\"List of Combinations accepting H1: {chi2s}\")"
      ],
      "metadata": {
        "id": "9Ob8f7QQ-pBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi2s"
      ],
      "metadata": {
        "id": "4AwLPWcoAWV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in chi2s:\n",
        "    value = chi2s[k]\n",
        "    if value > 500:\n",
        "        print(k)"
      ],
      "metadata": {
        "id": "k05m8Z-T-pEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_obj = df_categorical[['Vehicle.Type','TRIM.SERIES','Engine','SteeringGear','Tire','Wheel','LaneDeparture', 'MY', 'TIS', 'Warranty']]"
      ],
      "metadata": {
        "id": "Nwn8bf4zAOmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply the unsupervised machine learning model\n",
        "mca = prince.MCA(n_components=2).fit(df_obj)"
      ],
      "metadata": {
        "id": "OfnxuCENJDFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimension Quantity\n",
        "quant_dim = mca.J_ - mca.K_"
      ],
      "metadata": {
        "id": "abYuNovHJDIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mca.total_inertia_/quant_dim)"
      ],
      "metadata": {
        "id": "1iJSYDZJJDLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total of Categories: {mca.J_}\")\n",
        "print(f\"Total of Variables: {mca.K_}\")\n",
        "print(f\"Total of Dimensions: {quant_dim}\")"
      ],
      "metadata": {
        "id": "z2PDKRC8JDN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the eigenvalues\n",
        "table_eigenvalues = mca.eigenvalues_summary\n",
        "table_eigenvalues"
      ],
      "metadata": {
        "id": "St05MDJCJDQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Total main inertia\n",
        "#Sum of all eigenvalues (all existing dimensions)\n",
        "\n",
        "print(mca.total_inertia_)"
      ],
      "metadata": {
        "id": "TqDGWgyYJN_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the main coordinates of the variable categories\n",
        "coord_burt = mca.column_coordinates(df_obj)"
      ],
      "metadata": {
        "id": "UJCY3qWIJOB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the coordinates of the observations come from the standard coordinates\n",
        "coord_obs = mca.row_coordinates(df_obj)"
      ],
      "metadata": {
        "id": "zwNYQqtQJOEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining the standard coordinates of variable categories\n",
        "coord_padrao = mca.column_coordinates(df_obj)/np.sqrt(mca.eigenvalues_)"
      ],
      "metadata": {
        "id": "-L-wKm7rJOHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the perceptual map (standard coordinates)\n",
        "# Note: for the above function to be executed properly, do not leave an underline in the original name of the variable in the dataset!\n",
        "chart = coord_padrao.reset_index()\n",
        "\n",
        "nome_categ=[]\n",
        "for col in df_obj:\n",
        "    nome_categ.append(df_obj[col].sort_values(ascending=True).unique())\n",
        "    categorias = pd.DataFrame(nome_categ).stack().reset_index()\n",
        "\n",
        "var_chart = pd.Series(chart['index'].str.split('_', expand=True).iloc[:,0])\n",
        "\n",
        "chart_df_mca = pd.DataFrame({'category': chart['index'],\n",
        "                             'obs_x': chart[0],\n",
        "                             'obs_y': chart[1],\n",
        "                             'variable': var_chart,\n",
        "                             'category_id': categorias[0]})"
      ],
      "metadata": {
        "id": "4Cb2yw6gJOJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chart"
      ],
      "metadata": {
        "id": "L28p2hvrJDTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chart_df_mca"
      ],
      "metadata": {
        "id": "hVH3KbyLJbUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_point(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "        ax.text(point['x'] + 0.03, point['y'] - 0.02, point['val'], fontsize=5)\n",
        "\n",
        "label_point(x = chart_df_mca['obs_x'],\n",
        "            y = chart_df_mca['obs_y'],\n",
        "            val = chart_df_mca['category_id'],\n",
        "            ax = plt.gca())\n",
        "\n",
        "\n",
        "sns.scatterplot(data=chart_df_mca, x='obs_x', y='obs_y', hue='variable', s=20)\n",
        "sns.despine(top=True, right=True, left=False, bottom=False)\n",
        "plt.axhline(y=0, color='lightgrey', ls='--', linewidth=0.8)\n",
        "plt.axvline(x=0, color='lightgrey', ls='--', linewidth=0.8)\n",
        "plt.tick_params(size=2, labelsize=6)\n",
        "plt.legend(bbox_to_anchor=(1.25,-0.2), fancybox=True, shadow=True, ncols=10, fontsize='5')\n",
        "plt.title(\"Perceptual Map - MCA\", fontsize=12)\n",
        "plt.xlabel(f\"Dim. 1: {table_eigenvalues.iloc[0,1]} of Inertia\", fontsize=8)\n",
        "plt.ylabel(f\"Dim. 2: {table_eigenvalues.iloc[1,1]} of Inertia\", fontsize=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RBgzOZlDJbXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import prince\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px # Plotly pode ser melhor para biplots interativos\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "\n",
        "# Configurar o renderer do Plotly para exibir no ambiente Colab/Jupyter\n",
        "pio.renderers.default = 'colab'\n",
        "\n",
        "# --- Passo 1: Identificar e Preparar Colunas Categóricas (igual ao código anterior) ---\n",
        "\n",
        "# Liste manualmente as colunas que você sabe que são categóricas e transformadas\n",
        "# ou identifique-as programaticamente.\n",
        "#categorical_cols_for_mca = ['Vehicle.Type','TRIM.SERIES','Engine','SteeringGear','Tire','Wheel','LaneDeparture', 'MY', 'TIS', 'Warranty']\n",
        "categorical_cols_for_mca = [\n",
        "    'Vehicle_Type',\n",
        "    'TRIM_SERIES',\n",
        "    'WHEELBASE',\n",
        "    'Drive_',      # Se essas foram transformadas\n",
        "    'Vehicle_',\n",
        "    'Engine_',\n",
        "    'Cab_',\n",
        "    'CabStyle',\n",
        "    'Engine',\n",
        "    'RearWheels',\n",
        "    'SteeringGear',\n",
        "    'Suspension',\n",
        "    'Tire',\n",
        "    'Transmission',\n",
        "    'Trim_Series_broadcast',\n",
        "    'Wheel',\n",
        "    'wheelbase_broadcast',\n",
        "    'LaneDeparture',\n",
        "    'MY',\n",
        "    'Warranty', # 'Warranty' também é categórica\n",
        "    'TIS'\n",
        "]\n",
        "\n",
        "# Opcional: Filtre para garantir que essas colunas existam em ambos os DataFrames\n",
        "# e no processed_df (que é o que usaremos como base)\n",
        "cols_present_in_real = [col for col in categorical_cols_for_mca if col in processed_df.columns]\n",
        "cols_present_in_synthetic = [col for col in cols_present_in_real if col in synthetic_data.columns]\n",
        "\n",
        "\n",
        "\n",
        "if len(cols_present_in_synthetic) < len(categorical_cols_for_mca):\n",
        "    missing_cols = [col for col in categorical_cols_for_mca if col not in cols_present_in_synthetic]\n",
        "    print(f\"Aviso: As seguintes colunas categóricas selecionadas não estão presentes em ambos os DataFrames (Real e Sintético): {missing_cols}. Elas serão excluídas da análise MCA.\")\n",
        "\n",
        "categorical_cols_for_mca = cols_present_in_synthetic\n",
        "\n",
        "if not categorical_cols_for_mca:\n",
        "    print(\"Erro: Nenhuma coluna categórica comum encontrada nos DataFrames Real e Sintético para realizar a MCA.\")\n",
        "else:\n",
        "    print(f\"Colunas categóricas comuns selecionadas para MCA: {categorical_cols_for_mca}\")\n",
        "\n",
        "    # Crie sub-DataFrames apenas com as colunas categóricas comuns\n",
        "    df_categorical_real = processed_df[categorical_cols_for_mca].copy()\n",
        "    df_categorical_synthetic = synthetic_data[categorical_cols_for_mca].copy()\n",
        "\n",
        "    # Rename the columns to not interfere the algorithm to plot data\n",
        "    df_categorical_real.rename(columns=lambda x: x.replace('_', '.'), inplace=True)\n",
        "    df_categorical_synthetic.rename(columns=lambda x: x.replace('_', '.'), inplace=True)\n",
        "\n",
        "    # Tratar NaNs (se necessário, igual ao código anterior)\n",
        "    print(\"\\nTratando NaNs em colunas categóricas (Real)...\")\n",
        "    for col in df_categorical_real.columns:\n",
        "        if df_categorical_real[col].isnull().any():\n",
        "            mode_val = df_categorical_real[col].mode()\n",
        "            if not mode_val.empty:\n",
        "                df_categorical_real[col].fillna(mode_val[0], inplace=True)\n",
        "            else:\n",
        "                df_categorical_real[col].fillna('NaN_Filled_Real', inplace=True)\n",
        "\n",
        "    print(\"Tratando NaNs em colunas categóricas (Sintético)...\")\n",
        "    for col in df_categorical_synthetic.columns:\n",
        "        if df_categorical_synthetic[col].isnull().any():\n",
        "            mode_val = df_categorical_synthetic[col].mode()\n",
        "            if not mode_val.empty:\n",
        "                df_categorical_synthetic[col].fillna(mode_val[0], inplace=True)\n",
        "            else:\n",
        "                df_categorical_synthetic[col].fillna('NaN_Filled_Synthetic', inplace=True)\n",
        "\n",
        "\n",
        "    # --- Passo 2: Treinar Modelos MCA Separados ---\n",
        "\n",
        "    # Inicializar e Ajustar o Modelo MCA para Dados Reais\n",
        "    mca_real = prince.MCA(n_components=2, n_iter=10, random_state=42)\n",
        "    print(\"\\nAjustando o modelo MCA para Dados Reais...\")\n",
        "    mca_real = mca_real.fit(df_categorical_real)\n",
        "    print(\"Ajuste MCA (Real) completo.\")\n",
        "\n",
        "    # Inicializar e Ajustar o Modelo MCA para Dados Sintéticos\n",
        "    mca_synthetic = prince.MCA(n_components=2, n_iter=10, random_state=42)\n",
        "    print(\"Ajustando o modelo MCA para Dados Sintéticos...\")\n",
        "    mca_synthetic = mca_synthetic.fit(df_categorical_synthetic)\n",
        "    print(\"Ajuste MCA (Sintético) completo.\")\n",
        "\n",
        "    # --- Passo 3: Obter Coordenadas das Categorias e Inércia ---\n",
        "\n",
        "    # Coordenadas das categorias para Dados Reais\n",
        "    category_coords_real = mca_real.column_coordinates(df_categorical_real)\n",
        "    category_coords_real['Data_Source'] = 'Real'\n",
        "    category_coords_real.columns = ['Dim 1', 'Dim 2', 'Data_Source']\n",
        "\n",
        "    # Coordenadas das categorias para Dados Sintéticos\n",
        "    category_coords_synthetic = mca_synthetic.column_coordinates(df_categorical_synthetic)\n",
        "    category_coords_synthetic['Data_Source'] = 'Synthetic'\n",
        "    category_coords_synthetic.columns = ['Dim 1', 'Dim 2', 'Data_Source']\n",
        "\n",
        "    # Combinar as coordenadas das categorias para plotagem comparativa\n",
        "    combined_category_coords = pd.concat([category_coords_real, category_coords_synthetic])\n",
        "\n",
        "    # Obter a inércia explicada\n",
        "    # Calcular a inércia explicada usando a fórmula: eigenvalues_ / total_inertia_\n",
        "    total_inertia_real = mca_real.total_inertia_\n",
        "    explained_inertia_real = mca_real.eigenvalues_ / total_inertia_real\n",
        "\n",
        "    total_inertia_synthetic = mca_synthetic.total_inertia_\n",
        "    explained_inertia_synthetic = mca_synthetic.eigenvalues_ / total_inertia_synthetic\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nInércia explicada por dimensão (Real vs. Sintético):\")\n",
        "    for i in range(min(len(explained_inertia_real), len(explained_inertia_synthetic))):\n",
        "        print(f\"  Dimensão {i+1}: Real={explained_inertia_real[i]:.4f}, Sintético={explained_inertia_synthetic[i]:.4f}\")\n",
        "\n",
        "\n",
        "    # --- Passo 4: Visualizar as Coordenadas das Categorias Lado a Lado ou Sobrepostas ---\n",
        "\n",
        "    print(\"\\nGerando Scatter Plot Comparativo para Coordenadas das Categorias...\")\n",
        "\n",
        "    # Opção 1: Scatter Plot Comparativo (Real e Sintético no mesmo gráfico, diferenciados por cor)\n",
        "    # Use Plotly para um gráfico interativo (útil para ver os nomes das categorias ao passar o mouse)\n",
        "    fig = px.scatter(\n",
        "        combined_category_coords.reset_index(), # Resetar índice para que o nome da categoria vire coluna\n",
        "        x='Dim 1',\n",
        "        y='Dim 2',\n",
        "        color='Data_Source', # Diferenciar por cor\n",
        "        text='index',       # Usar o nome da categoria como texto para rótulos\n",
        "        title='MCA - Comparação de Coordenadas das Categorias (Real vs. Sintético)',\n",
        "        labels={'index': 'Categoria'}, # Rótulo para o tooltip\n",
        "        hover_name='index', # Mostrar o nome da categoria no tooltip\n",
        "        size_max=10 # Tamanho máximo dos pontos\n",
        "    )\n",
        "\n",
        "    # Melhorar o layout (opcional)\n",
        "    fig.update_traces(textposition='top center') # Posição dos rótulos\n",
        "    fig.update_layout(\n",
        "        xaxis_title=f'Dimensão 1 (Real: {explained_inertia_real[0]*100:.2f}%, Sintético: {explained_inertia_synthetic[0]*100:.2f}%)',\n",
        "        yaxis_title=f'Dimensão 2 (Real: {explained_inertia_real[1]*100:.2f}%, Sintético: {explained_inertia_synthetic[1]*100:.2f}%)',\n",
        "        hovermode='closest' # Melhorar o comportamento do tooltip\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "    # Opção 2: Scatter Plots Lado a Lado (usando Matplotlib)\n",
        "    # Se preferir Matplotlib, você pode plotar os dois conjuntos de coordenadas separadamente\n",
        "    # em subplots, similar ao heatmap de correlação.\n",
        "\n",
        "    fig_mpl, axes_mpl = plt.subplots(1, 2, figsize=(20, 10)) # 1 linha, 2 colunas\n",
        "\n",
        "    # Plotar Coordenadas Reais\n",
        "    sns.scatterplot(data=category_coords_real, x='Dim 1', y='Dim 2', ax=axes_mpl[0])\n",
        "    for i, (index, row) in enumerate(category_coords_real.iterrows()):\n",
        "         axes_mpl[0].text(row['Dim 1'] + 0.005, row['Dim 2'] + 0.005, index, fontsize=8)\n",
        "    axes_mpl[0].set_title('MCA - Coordenadas das Categorias (Real)')\n",
        "    axes_mpl[0].set_xlabel(f'Dimensão 1 ({explained_inertia_real[0]*100:.2f}% Inércia)')\n",
        "    axes_mpl[0].set_ylabel(f'Dimensão 2 ({explained_inertia_real[1]*100:.2f}% Inércia)')\n",
        "    axes_mpl[0].grid(True, linestyle='--', alpha=0.6)\n",
        "    axes_mpl[0].axhline(0, color='gray', linestyle='-', linewidth=0.8)\n",
        "    axes_mpl[0].axvline(0, color='gray', linestyle='-', linewidth=0.8)\n",
        "\n",
        "\n",
        "    # Plotar Coordenadas Sintéticas\n",
        "    sns.scatterplot(data=category_coords_synthetic, x='Dim 1', y='Dim 2', ax=axes_mpl[1])\n",
        "    for i, (index, row) in enumerate(category_coords_synthetic.iterrows()):\n",
        "         axes_mpl[1].text(row['Dim 1'] + 0.005, row['Dim 2'] + 0.005, index, fontsize=8)\n",
        "    axes_mpl[1].set_title('MCA - Coordenadas das Categorias (Sintético)')\n",
        "    axes_mpl[1].set_xlabel(f'Dimensão 1 ({explained_inertia_synthetic[0]*100:.2f}% Inércia)')\n",
        "    axes_mpl[1].set_ylabel(f'Dimensão 2 ({explained_inertia_synthetic[1]*100:.2f}% Inércia)')\n",
        "    axes_mpl[1].grid(True, linestyle='--', alpha=0.6)\n",
        "    axes_mpl[1].axhline(0, color='gray', linestyle='-', linewidth=0.8)\n",
        "    axes_mpl[1].axvline(0, color='gray', linestyle='-', linewidth=0.8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Análise Comparativa ---\")\n",
        "    print(\"Observe a proximidade dos pontos de categorias correspondentes nos gráficos (especialmente no Plotly interativo ou nos gráficos lado a lado do Matplotlib).\")\n",
        "    print(\"Se uma categoria (ex: 'Engine_V8') está próxima de outra (ex: 'Transmission_0') nos dados reais e as categorias correspondentes ('Engine_V8', 'Transmission_0') estão próximas nos dados sintéticos, isso indica que a associação foi bem preservada.\")\n",
        "    print(\"Compare também a inércia explicada pelas primeiras dimensões. Valores semelhantes sugerem que a estrutura geral das associações foi replicada.\")"
      ],
      "metadata": {
        "id": "bMww125zJbZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import prince\n",
        "# Importar bibliotecas de visualização, se necessário para plotar as diferenças\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assumindo que você já executou o código anterior e tem:\n",
        "# processed_df (seu DataFrame real limpo e com colunas renomeadas '_ ' para '.')\n",
        "# synthetic_data (seu DataFrame sintético)\n",
        "# mca_real (modelo MCA ajustado nos dados reais)\n",
        "# mca_synthetic (modelo MCA ajustado nos dados sintéticos)\n",
        "\n",
        "# --- Passo 1: Obter as Coordenadas das Categorias de Ambos os Modelos ---\n",
        "\n",
        "# Certifique-se de que as colunas categóricas usadas para treinar o MCA são as mesmas\n",
        "# e que foram renomeadas consistentemente (underline para ponto).\n",
        "# Vamos reutilizar a lista de colunas usadas no bloco anterior de comparação de MCA\n",
        "categorical_cols_for_mca_renamed = [\n",
        "    'Vehicle.Type', 'TRIM.SERIES', 'WHEELBASE', 'Drive.', 'Vehicle.',\n",
        "    'Engine.', 'Cab.', 'CabStyle', 'Engine', 'RearWheels', 'SteeringGear',\n",
        "    'Suspension', 'Tire', 'Transmission', 'Trim.Series.broadcast',\n",
        "    'Wheel', 'wheelbase.broadcast', 'LaneDeparture', 'MY', 'TIS', 'Warranty'\n",
        "]\n",
        "# Filtrar para garantir que essas colunas renomeadas existem nos DataFrames MCA\n",
        "# que foram usados para gerar as coordenadas (assumimos que são df_categorical_real/synthetic)\n",
        "# e que os modelos mca_real/synthetic foram treinados com essas colunas.\n",
        "# Nota: O renomeamento para '.' é crucial para que as coordenadas tenham os mesmos nomes.\n",
        "\n",
        "try:\n",
        "    # Obter as coordenadas das categorias (padrão ou principais)\n",
        "    # As 'standard coordinates' (divididas pela raiz do eigenvalue) são boas para visualização\n",
        "    # As 'principal coordinates' (coordenadas de Burt) também podem ser usadas\n",
        "    # Vamos usar as coordenadas principais (de Burt) aqui para comparação direta de posição.\n",
        "    # Certifique-se de que as colunas usadas aqui correspondem às que foram usadas para treinar o MCA.\n",
        "    # Assume-se que mca_real e mca_synthetic foram treinados em df_categorical_real e df_categorical_synthetic\n",
        "    # que já tiveram suas colunas renomeadas para '.'\n",
        "\n",
        "    category_coords_real = mca_real.column_coordinates(df_categorical_real)\n",
        "    category_coords_synthetic = mca_synthetic.column_coordinates(df_categorical_synthetic)\n",
        "\n",
        "    # Renomear as colunas de dimensão para serem consistentes (Dim 1, Dim 2)\n",
        "    category_coords_real.columns = [f'Dim {i+1}' for i in range(category_coords_real.shape[1])]\n",
        "    category_coords_synthetic.columns = [f'Dim {i+1}' for i in range(category_coords_synthetic.shape[1])]\n",
        "\n",
        "    print(f\"Coordenadas Reais obtidas: Shape {category_coords_real.shape}\")\n",
        "    print(f\"Coordenadas Sintéticas obtidas: Shape {category_coords_synthetic.shape}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"Erro: Certifique-se de que 'processed_df', 'synthetic_data', 'mca_real', 'mca_synthetic', 'df_categorical_real', e 'df_categorical_synthetic' foram definidos e que os modelos MCA foram ajustados antes de executar este bloco.\")\n",
        "    # Se ocorrer um erro, pare a execução deste bloco\n",
        "    raise\n",
        "\n",
        "# --- Passo 2: Identificar Categorias Comuns em Ambas as Coordenadas ---\n",
        "\n",
        "# Os índices dos DataFrames de coordenadas são os nomes das categorias.\n",
        "common_categories = list(category_coords_real.index.intersection(category_coords_synthetic.index))\n",
        "\n",
        "if not common_categories:\n",
        "    print(\"\\nErro: Nenhuma categoria comum encontrada nos resultados de coordenadas MCA. Verifique se os modelos MCA foram treinados em DataFrames com nomes de colunas e categorias consistentes.\")\n",
        "else:\n",
        "    print(f\"\\nComparando coordenadas para {len(common_categories)} categorias comuns.\")\n",
        "\n",
        "    # Filtrar as coordenadas para incluir apenas as categorias comuns\n",
        "    coords_real_common = category_coords_real.loc[common_categories]\n",
        "    coords_synthetic_common = category_coords_synthetic.loc[common_categories]\n",
        "\n",
        "    # Garantir que a ordem das categorias é a mesma para comparação ponto a ponto\n",
        "    coords_real_common = coords_real_common.sort_index()\n",
        "    coords_synthetic_common = coords_synthetic_common.sort_index()\n",
        "\n",
        "\n",
        "    # --- Passo 3: Calcular a Distância entre as Coordenadas Correspondentes ---\n",
        "\n",
        "    # Calcular a distância Euclidiana para as primeiras n_components (Dim 1 e Dim 2)\n",
        "    # Você pode estender isso para mais dimensões se n_components > 2\n",
        "    n_dims_to_compare = min(mca_real.n_components, mca_synthetic.n_components)\n",
        "    print(f\"Calculando distância Euclidiana usando as primeiras {n_dims_to_compare} dimensões.\")\n",
        "\n",
        "    # Calcular a diferença nas coordenadas\n",
        "    coord_difference = coords_real_common.iloc[:, :n_dims_to_compare] - coords_synthetic_common.iloc[:, :n_dims_to_compare]\n",
        "\n",
        "    # Calcular a distância Euclidiana (raiz quadrada da soma dos quadrados das diferenças)\n",
        "    # axis=1 soma ao longo das colunas para cada linha (categoria)\n",
        "    distances = np.sqrt((coord_difference**2).sum(axis=1))\n",
        "\n",
        "    # Criar um DataFrame para visualizar as distâncias\n",
        "    distance_df = pd.DataFrame({\n",
        "        'Categoria': distances.index,\n",
        "        'Distancia_Euclidiana': distances.values\n",
        "    })\n",
        "\n",
        "    # Ordenar por distância para ver quais categorias têm as maiores/menores diferenças\n",
        "    distance_df = distance_df.sort_values(by='Distancia_Euclidiana', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n--- Maiores Diferenças nas Coordenadas das Categorias (Distância Euclidiana) ---\")\n",
        "    # Exibir as categorias com maiores distâncias (estrutura menos bem replicada)\n",
        "    print(distance_df.head(10)) # Exibir as 10 maiores diferenças\n",
        "\n",
        "    print(\"\\n--- Menores Diferenças nas Coordenadas das Categorias (Distância Euclidiana) ---\")\n",
        "    # Exibir as categorias com menores distâncias (estrutura mais bem replicada)\n",
        "    print(distance_df.tail(10)) # Exibir as 10 menores diferenças (excluindo possivelmente 0 se forem idênticas)\n",
        "\n",
        "\n",
        "    # --- Passo 4: Análise Visual (Opcional) ---\n",
        "\n",
        "    # Você pode querer visualizar a distribuição dessas distâncias\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(distance_df['Distancia_Euclidiana'], kde=True)\n",
        "    plt.title('Distribuição das Distâncias nas Coordenadas das Categorias (Real vs. Sintético)')\n",
        "    plt.xlabel('Distância Euclidiana nas Coordenadas MCA (Dim 1 e Dim 2)')\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.show()\n",
        "\n",
        "    # Ou um boxplot para resumir\n",
        "    plt.figure(figsize=(5, 6))\n",
        "    sns.boxplot(y=distance_df['Distancia_Euclidiana'])\n",
        "    plt.title('Boxplot das Distâncias nas Coordenadas das Categorias')\n",
        "    plt.ylabel('Distância Euclidiana')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print(\"\\n--- Análise das Distâncias ---\")\n",
        "    print(f\"Distância Euclidiana Média: {distance_df['Distancia_Euclidiana'].mean():.4f}\")\n",
        "    print(f\"Distância Euclidiana Mediana: {distance_df['Distancia_Euclidiana'].median():.4f}\")\n",
        "    print(f\"Distância Euclidiana Máxima: {distance_df['Distancia_Euclidiana'].max():.4f}\")\n",
        "\n",
        "    print(\"\\nInterpretação:\")\n",
        "    print(\"- Distâncias pequenas indicam que a posição (e, portanto, as principais associações) daquela categoria foi bem replicada pelo modelo sintético.\")\n",
        "    print(\"- Distâncias grandes indicam que a posição (e associações) daquela categoria é significativamente diferente no dataset sintético.\")\n",
        "    print(\"- A distribuição geral das distâncias e a média/mediana dão uma ideia do quão bem a estrutura de associação CATEGRICAL geral foi replicada.\")\n",
        "    print(\"- Categorias com as maiores distâncias são aquelas onde o modelo sintético falhou mais em replicar sua estrutura de associação.\")"
      ],
      "metadata": {
        "id": "FBrMA-0mSHOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "\n",
        "# Configurar o renderer do Plotly\n",
        "pio.renderers.default = 'colab'\n",
        "\n",
        "# --- Assumindo que você já executou o código anterior e tem: ---\n",
        "# category_coords_real (DataFrame com coordenadas das categorias Reais, colunas 'Dim 1', 'Dim 2', ...)\n",
        "# category_coords_synthetic (DataFrame com coordenadas das categorias Sintéticas, colunas 'Dim 1', 'Dim 2', ...)\n",
        "# common_categories (lista das categorias presentes em ambos os DataFrames de coordenadas)\n",
        "# distance_df (DataFrame com 'Categoria' e 'Distancia_Euclidiana')\n",
        "\n",
        "# --- Passo 1: Preparar os Dados para o Plot de Vetores ---\n",
        "\n",
        "if 'common_categories' not in locals() or not common_categories:\n",
        "     print(\"Erro: A lista 'common_categories' não foi encontrada ou está vazia. Execute os blocos anteriores para obter as coordenadas e identificar as categorias comuns.\")\n",
        "else:\n",
        "    # Filtrar as coordenadas para incluir apenas as categorias comuns e garantir a ordem\n",
        "    coords_real_common = category_coords_real.loc[common_categories, ['Dim 1', 'Dim 2']].sort_index()\n",
        "    coords_synthetic_common = category_coords_synthetic.loc[common_categories, ['Dim 1', 'Dim 2']].sort_index()\n",
        "    distance_df_common = distance_df.set_index('Categoria').loc[common_categories].sort_index() # Garantir que distance_df tbm esteja na mesma ordem\n",
        "\n",
        "    # Criar um DataFrame que combine as coordenadas Real e Sintética e a distância\n",
        "    plot_data = pd.DataFrame({\n",
        "        'Categoria': common_categories,\n",
        "        'x_real': coords_real_common['Dim 1'].values,\n",
        "        'y_real': coords_real_common['Dim 2'].values,\n",
        "        'x_synthetic': coords_synthetic_common['Dim 1'].values,\n",
        "        'y_synthetic': coords_synthetic_common['Dim 2'].values,\n",
        "        'distance': distance_df_common['Distancia_Euclidiana'].values\n",
        "    })\n",
        "\n",
        "    # Adicionar colunas para o final dos vetores (x_synthetic - x_real, y_synthetic - y_real)\n",
        "    # Ou podemos simplesmente plotar uma linha do real para o sintético\n",
        "    # Vamos plotar linhas para conectar o ponto real ao ponto sintético\n",
        "\n",
        "    print(f\"\\nPreparando dados para plotagem de diferenças para {len(plot_data)} categorias comuns.\")\n",
        "\n",
        "    # --- Passo 2: Criar o Gráfico Interativo com Plotly ---\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Adicionar os pontos Reais\n",
        "    fig.add_trace(go.Scattergl( # Usando Scattergl para melhor performance com muitos pontos\n",
        "        x=plot_data['x_real'],\n",
        "        y=plot_data['y_real'],\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=5,\n",
        "            opacity=0.6,\n",
        "            color='blue'\n",
        "        ),\n",
        "        name='Real',\n",
        "        hoverinfo='text',\n",
        "        text=[f'Real: {cat}<br>Dim 1: {x:.3f}<br>Dim 2: {y:.3f}'\n",
        "              for cat, x, y in zip(plot_data['Categoria'], plot_data['x_real'], plot_data['y_real'])]\n",
        "    ))\n",
        "\n",
        "    # Adicionar os pontos Sintéticos\n",
        "    fig.add_trace(go.Scattergl(\n",
        "        x=plot_data['x_synthetic'],\n",
        "        y=plot_data['y_synthetic'],\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=5,\n",
        "            opacity=0.6,\n",
        "            color='red'\n",
        "        ),\n",
        "        name='Synthetic',\n",
        "         hoverinfo='text',\n",
        "        text=[f'Synthetic: {cat}<br>Dim 1: {x:.3f}<br>Dim 2: {y:.3f}'\n",
        "              for cat, x, y in zip(plot_data['Categoria'], plot_data['x_synthetic'], plot_data['y_synthetic'])]\n",
        "    ))\n",
        "\n",
        "    # Adicionar as linhas (vetores conceituais) conectando Real ao Sintético\n",
        "    # Iterar sobre as linhas do DataFrame plot_data\n",
        "    for index, row in plot_data.iterrows():\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=[row['x_real'], row['x_synthetic']],\n",
        "            y=[row['y_real'], row['y_synthetic']],\n",
        "            mode='lines',\n",
        "            line=dict(\n",
        "                width=0.8,\n",
        "                color=f'rgba(0, 0, 0, {0.2 + 0.8 * (row[\"distance\"] / distance_df[\"Distancia_Euclidiana\"].max())})' # Opacidade baseada na distância\n",
        "                 # Você pode mapear a cor para a distância tbm\n",
        "            ),\n",
        "            showlegend=False, # Não mostrar legenda para cada linha\n",
        "            hoverinfo='text',\n",
        "            text=f'Categoria: {row[\"Categoria\"]}<br>Distância: {row[\"distance\"]:.4f}'\n",
        "        ))\n",
        "\n",
        "    # --- Configurar Layout do Gráfico ---\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='MCA - Comparação da distância das Coordenadas das Categorias (Real vs. Sintético)',\n",
        "        xaxis_title='Dimensão 1', # Poderia adicionar a inércia explicada aqui, mas o título ficaria longo\n",
        "        yaxis_title='Dimensão 2',\n",
        "        hovermode='closest', # Melhorar o comportamento do tooltip\n",
        "        showlegend=True,\n",
        "        width=800, # Ajuste o tamanho conforme necessário\n",
        "        height=600\n",
        "    )\n",
        "\n",
        "    # Adicionar linhas de referência nos eixos 0,0\n",
        "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
        "    fig.add_vline(x=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
        "\n",
        "\n",
        "    # Exibir o gráfico\n",
        "    print(\"\\nExibindo o gráfico interativo de diferenças...\")\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "PG6IZZPIJbex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Assumindo que você já executou o código anterior que calculou as distâncias ---\n",
        "# E que o DataFrame 'distance_df' foi criado e contém as colunas 'Categoria' e 'Distancia_Euclidiana'.\n",
        "\n",
        "# Verificar se o DataFrame 'distance_df' existe\n",
        "if 'distance_df' in locals():\n",
        "    print(\"--- Tabela de Diferenças Absolutas nas Coordenadas das Categorias (Sintético vs Real) ---\")\n",
        "\n",
        "    # O DataFrame 'distance_df' já está ordenado em ordem decrescente pela distância\n",
        "    # E já tem o índice resetado, então está pronto para exibição.\n",
        "    # Renomear a coluna de distância para clareza no output\n",
        "    table_of_differences = distance_df.rename(columns={'Distancia_Euclidiana': 'Distancia_Euclidiana_Real_vs_Sintetico'})\n",
        "\n",
        "    # Exibir a tabela completa ou as primeiras/últimas linhas se for muito grande\n",
        "    # Para exibir a tabela completa:\n",
        "    # print(table_of_differences.to_string())\n",
        "\n",
        "    # Para exibir as primeiras 15 e últimas 15 linhas (se houver muitas categorias):\n",
        "    if len(table_of_differences) > 30:\n",
        "        print(\"Exibindo as 15 maiores e 15 menores diferenças:\")\n",
        "        print(table_of_differences.head(15).to_string(index=False))\n",
        "        print(\"\\n...\\n\")\n",
        "        print(table_of_differences.tail(15).to_string(index=False))\n",
        "    else:\n",
        "        # Se a tabela for pequena, exibe tudo\n",
        "        print(table_of_differences.to_string(index=False))\n",
        "\n",
        "    print(\"\\n--- Fim da Tabela ---\")\n",
        "\n",
        "else:\n",
        "    print(\"Erro: O DataFrame 'distance_df' não foi encontrado. Certifique-se de executar o código anterior que calcula as distâncias das coordenadas.\")"
      ],
      "metadata": {
        "id": "nEmDLW1SJbhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_of_differences"
      ],
      "metadata": {
        "id": "YfyAYtKTTmOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Assumindo que 'table_of_differences' foi criada no bloco anterior ---\n",
        "# E contém as colunas 'Categoria' e 'Distancia_Euclidiana_Real_vs_Sintetico'.\n",
        "\n",
        "if 'table_of_differences' in locals():\n",
        "    print(\"--- Análise de Variáveis com Maiores Diferenças nas Coordenadas ---\")\n",
        "\n",
        "    # Criar uma cópia para não modificar o DataFrame original se necessário\n",
        "    diff_analysis_df = table_of_differences.copy()\n",
        "\n",
        "    # Dividir a coluna 'Categoria' no delimitador '__' e pegar a primeira parte\n",
        "    # Usamos str.split('__', expand=True) para criar colunas separadas\n",
        "    # e pegamos a primeira coluna (iloc[:, 0])\n",
        "    # Lidamos com o caso onde '__' não existe (o split retornaria apenas uma parte)\n",
        "    diff_analysis_df['Nome_Variavel'] = diff_analysis_df['Categoria'].str.split('__', expand=True).iloc[:, 0]\n",
        "\n",
        "    # Se após o split a parte for igual ao nome original da categoria,\n",
        "    # pode ser que não houvesse '__'. Precisamos pensar em como tratar isso.\n",
        "    # No seu código original de transformação, o formato era 'columnname_index'.\n",
        "    # No MCA com colunas renomeadas para '.', o formato seria 'columnname.index'.\n",
        "    # Vamos assumir que você quer separar o nome original da variável do índice numérico gerado.\n",
        "    # O split deve ser feito no último '.' se o formato for 'NomeVariavel.indice'.\n",
        "\n",
        "    # Corrigindo o split baseado no formato 'NomeVariavel.indice' após renomeamento para '.'\n",
        "    # Vamos dividir no último '.' e pegar a parte ANTES do último '.'\n",
        "    # Ex: 'Vehicle.Type.0' -> 'Vehicle.Type'\n",
        "    # Ex: 'MY.2022' -> 'MY'\n",
        "    # Ex: 'TIS.0' -> 'TIS'\n",
        "    # Vamos usar rsplit para dividir apenas no último ponto.\n",
        "    diff_analysis_df['Nome_Variavel_Original'] = diff_analysis_df['Categoria'].str.rsplit('.', n=1, expand=True).iloc[:, 0]\n",
        "\n",
        "    # Se a categoria for 'MY.2022', rsplit('.', n=1) dará 'MY' e '2022'.\n",
        "    # Se for 'Vehicle.Type.0', dará 'Vehicle.Type' e '0'.\n",
        "    # Parece que pegar a primeira parte após rsplit('.', n=1) é o que você precisa para o nome da variável original.\n",
        "\n",
        "    print(\"\\nDataFrame com nome original da variável adicionado:\")\n",
        "    print(diff_analysis_df.head().to_string()) # Exibir as primeiras linhas para verificar\n",
        "\n",
        "    # --- Contar a frequência das variáveis na lista ordenada por diferença ---\n",
        "\n",
        "    print(\"\\nContagem das Variáveis nas Categorias com Maiores Diferenças:\")\n",
        "\n",
        "    # Você quer contar a frequência das variáveis que aparecem nas categorias\n",
        "    # com maior distância. Podemos simplesmente contar as ocorrências de 'Nome_Variavel_Original'\n",
        "    # no DataFrame já ordenado. As variáveis no topo da contagem correspondem\n",
        "    # àquelas cujas categorias estão entre as que mais se moveram.\n",
        "\n",
        "    variable_difference_counts = diff_analysis_df['Nome_Variavel_Original'].value_counts()\n",
        "\n",
        "    print(variable_difference_counts)\n",
        "\n",
        "    print(\"\\n--- Análise da Contagem ---\")\n",
        "    print(\"As variáveis com maior contagem na lista acima são aquelas cujas categorias estão mais frequentemente entre as que apresentaram maiores diferenças de posição no mapa MCA entre os dados Real e Sintético.\")\n",
        "    print(\"Isso sugere que a estrutura de associação dessas variáveis específicas pode não ter sido tão bem replicada quanto a de outras variáveis.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Erro: O DataFrame 'table_of_differences' não foi encontrado. Certifique-se de executar os blocos anteriores.\")"
      ],
      "metadata": {
        "id": "jG4ZkG9tJbjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variable_difference_counts"
      ],
      "metadata": {
        "id": "pcUqhR2OX03z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qimwVlt-VLUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWNxvqFLVLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tow6T-hbVLaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Dc8020CVLck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdoIpmgZVLfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOE5ZYjHVLiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_details = quality_report.get_details(property_name='Column Pair Trends')"
      ],
      "metadata": {
        "id": "Dcv83ajPz6LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_details.to_csv('quality_details.csv', index=False)"
      ],
      "metadata": {
        "id": "bWgWNmAG0F5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_report.get_info()"
      ],
      "metadata": {
        "id": "s621QD1F0QBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_report.get_properties()"
      ],
      "metadata": {
        "id": "Tv08e3x90YVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "thbnva5b0E93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic.get_properties()"
      ],
      "metadata": {
        "id": "jWY6Z-UJ0gNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=diagnostic.get_visualization(property_name='Data Validity')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FNaIGHVB0qdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic_details = diagnostic.get_details(property_name='Data Validity')"
      ],
      "metadata": {
        "id": "8KfTwgvMyhWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic_details.to_csv('diagnostic_details.csv', index=False)"
      ],
      "metadata": {
        "id": "kOSGhau_yf1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic.get_info()"
      ],
      "metadata": {
        "id": "TcABCr_Iy000"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic.report_info"
      ],
      "metadata": {
        "id": "dtZ9Bpd0zBKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. plot the data\n",
        "fig = get_column_plot(\n",
        "    real_data=processed_df,\n",
        "    synthetic_data=synthetic_data,\n",
        "    metadata=metadata,\n",
        "    column_name='Warranty'\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Al2TlOe-vG52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sdmetrics.reports.single_table import DiagnosticReport\n",
        "\n",
        "report = DiagnosticReport()"
      ],
      "metadata": {
        "id": "IkvoD2fSvb32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "LfJ9fhaMvrt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data.to_csv('alignment_synthetic_data.csv', index=False)"
      ],
      "metadata": {
        "id": "qOGpxLOacdd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data.Warranty.value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "6ZeGuHkMhr0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthesizer.get_parameters()"
      ],
      "metadata": {
        "id": "hEZV18dLcdgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data.isnull().sum()"
      ],
      "metadata": {
        "id": "CGl2a81dDQH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}