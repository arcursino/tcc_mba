{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arcursino/tcc_mba/blob/main/TCC_Ariana_Cursino_Modelagem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMsu1qu-pIHN"
      },
      "source": [
        "# Instalações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VDCtVCidHWtA"
      },
      "outputs": [],
      "source": [
        "!pip install bambi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf9ToTaR8FM4"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lP1wKp3pOXJ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtaBHaFSPd6y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandas.api.types import is_numeric_dtype, is_object_dtype, is_categorical_dtype\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, classification_report, mean_absolute_error, mean_squared_error\n",
        "import bambi as bmb\n",
        "import arviz as az"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DoaR4bSqm4n"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxyZD1ZNqzla"
      },
      "outputs": [],
      "source": [
        "# Import machine learning methods\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYqEM_MEQjKS"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7ErzGBW34CF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zovM0QF1pUlQ"
      },
      "source": [
        "# Pre-Processo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmaQ0_GhQp09"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtUe6CoNQsqL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/TCC_MBA/alignment_synthetic_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4JxC13HklBG"
      },
      "outputs": [],
      "source": [
        "def remover_colunas_numericas_constantes(df):\n",
        "    \"\"\"\n",
        "    Identifica e remove colunas numéricas de um DataFrame pandas\n",
        "    que possuem um valor constante em todas as linhas.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): O DataFrame de entrada.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Uma tupla contendo:\n",
        "            - pd.DataFrame: O DataFrame com as colunas constantes removidas.\n",
        "            - list: Uma lista com os nomes das colunas que foram removidas.\n",
        "    \"\"\"\n",
        "    print(\"Iniciando a avaliação das colunas...\")\n",
        "\n",
        "    # 1. Selecionar apenas as colunas que são de tipos numéricos\n",
        "    # Usamos np.number para incluir todos os tipos numéricos (int, float, etc.)\n",
        "    colunas_numericas = df.select_dtypes(include=np.number).columns\n",
        "    print(f\"Total de colunas numéricas encontradas: {len(colunas_numericas)}\")\n",
        "\n",
        "    # Lista para armazenar os nomes das colunas a serem removidas\n",
        "    colunas_para_remover = []\n",
        "\n",
        "    # 2. Iterar sobre as colunas numéricas e verificar se são constantes\n",
        "    print(\"Verificando colunas numéricas para constância...\")\n",
        "    for coluna in colunas_numericas:\n",
        "        # Verifica o número de valores únicos na coluna\n",
        "        # Se for 1, significa que todos os valores são iguais\n",
        "        if df[coluna].nunique() == 1:\n",
        "            colunas_para_remover.append(coluna)\n",
        "            print(f\"  - Coluna '{coluna}' é constante e será removida.\")\n",
        "        # else: # Opcional: para ver quais colunas numéricas NÃO são constantes\n",
        "        #     print(f\"  - Coluna '{coluna}' não é constante.\")\n",
        "\n",
        "\n",
        "    # 3. Remover as colunas identificadas do DataFrame original\n",
        "    if colunas_para_remover:\n",
        "        print(f\"\\nRemovendo {len(colunas_para_remover)} coluna(s) constante(s)...\")\n",
        "        df_limpo = df.drop(columns=colunas_para_remover)\n",
        "        print(\"Remoção concluída.\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma coluna numérica constante encontrada. O DataFrame permanece inalterado.\")\n",
        "        df_limpo = df.copy() # Retorna uma cópia para manter a consistência\n",
        "\n",
        "    print(\"\\nAvaliação e remoção finalizadas.\")\n",
        "\n",
        "    # Retorna o DataFrame limpo e a lista de colunas removidas\n",
        "    return df_limpo, colunas_para_remover"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMgDXc37ktJw"
      },
      "outputs": [],
      "source": [
        "df_limpo, colunas_removidas = remover_colunas_numericas_constantes(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8F56EvnphZf"
      },
      "source": [
        "# Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz1m0GID-QC9"
      },
      "source": [
        "## Train e Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQPEzGpO8qZG"
      },
      "outputs": [],
      "source": [
        "df_train = df_limpo[['cell_id', 'Vehicle_Type', 'Warranty',\n",
        "       'Rear_Thrust_Angle_Final_Value', 'RIDE_HEIGHT_FA_DIFF',\n",
        "       'RIDE_HEIGHT_FL', 'RIDE_HEIGHT_FL_INITIAL', 'RIDE_HEIGHT_FR',\n",
        "       'RIDE_HEIGHT_RA_DIFF', 'RIDE_HEIGHT_RL', 'RIDE_HEIGHT_RR',\n",
        "       'Steering_Wheel_Angle_Final_Value', 'Steering_Wheel_Angle_Preset_Value',\n",
        "       'Front_Sum_Toe_Final_Value', 'TOE_FA_TOTAL_INITIAL', 'L_F_Toe',\n",
        "       'TOE_FL_INITIAL', 'R_F_Toe', 'TOE_FR_INITIAL', 'TOE_RA_TOTAL',\n",
        "       'TOE_RA_TOTAL_INITIAL', 'L_R_Toe', 'TOE_RL_INITIAL', 'R_R_Toe',\n",
        "       'TOE_RR_INITIAL', 'CabStyle','Engine', 'RearWheels', 'SteeringGear',\n",
        "        'Suspension', 'Tire', 'Transmission', 'Wheel', 'LaneDeparture', 'MY']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "object_cols = df_train.select_dtypes(include='object').columns\n",
        "for col in object_cols:\n",
        "    df_train[col] = df_train[col].astype('category')"
      ],
      "metadata": {
        "id": "XbrecoR1cRg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk3Wj6pY7e4c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = train_test_split(df_train, random_state=42, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyFLF_bLFjL5"
      },
      "outputs": [],
      "source": [
        "id_and_categorical_cols = ['cell_id', 'Vehicle_Type', 'Warranty','CabStyle', 'Engine',\n",
        "                           'RearWheels', 'SteeringGear', 'Suspension', 'Tire',\n",
        "                           'Transmission', 'Wheel','LaneDeparture', 'MY']\n",
        "numeric_cols = []\n",
        "\n",
        "for col in X_train.columns:\n",
        "  if is_numeric_dtype(df_limpo[col]):\n",
        "    numeric_cols.append(col)\n",
        "\n",
        "# Separar as colunas\n",
        "X_train_numerical = X_train[numeric_cols]\n",
        "X_train_ids_and_cats = X_train[id_and_categorical_cols]\n",
        "\n",
        "# Separar as colunas\n",
        "X_test_numerical = X_test[numeric_cols]\n",
        "X_test_ids_and_cats = X_test[id_and_categorical_cols]\n",
        "\n",
        "# --- Passo 3: Aplique a escala APENAS às colunas numéricas ---\n",
        "scaler = StandardScaler() # Ou seu scaler de preferência\n",
        "X_train_scaled_numerical_array = scaler.fit_transform(X_train_numerical)\n",
        "X_test_scaled_numerical_array = scaler.fit_transform(X_test_numerical)\n",
        "\n",
        "# --- Passo 4: Converta o array escalado de volta para DataFrame e combine com as colunas originais ---\n",
        "# É crucial nomear as colunas do array escalado para poder combiná-las\n",
        "X_train_scaled_numerical_df = pd.DataFrame(X_train_scaled_numerical_array, columns=numeric_cols, index=X_train.index)\n",
        "X_test_scaled_numerical_df = pd.DataFrame(X_test_scaled_numerical_array, columns=numeric_cols, index=X_test.index)\n",
        "\n",
        "# Combine os dados numéricos escalados com as colunas de ID/categóricas originais\n",
        "# Use o index para garantir que as linhas correspondam\n",
        "X_train_processed = pd.concat([X_train_scaled_numerical_df, X_train_ids_and_cats], axis=1)\n",
        "X_test_processed = pd.concat([X_test_scaled_numerical_df, X_test_ids_and_cats], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ku7JFdpUhs"
      },
      "outputs": [],
      "source": [
        "target = X_train_processed.copy()\n",
        "target_teste = X_test_processed.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GNL42KBteA6"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR4LJSBJtkfo"
      },
      "outputs": [],
      "source": [
        "formula = 'Warranty ~ Rear_Thrust_Angle_Final_Value + RIDE_HEIGHT_FA_DIFF + RIDE_HEIGHT_FL_INITIAL +\\\n",
        "           RIDE_HEIGHT_FR + RIDE_HEIGHT_RA_DIFF + RIDE_HEIGHT_RL + RIDE_HEIGHT_RR + Steering_Wheel_Angle_Final_Value +\\\n",
        "           Steering_Wheel_Angle_Preset_Value + Front_Sum_Toe_Final_Value + TOE_FA_TOTAL_INITIAL + L_F_Toe +\\\n",
        "           TOE_FL_INITIAL + R_F_Toe + TOE_FR_INITIAL + TOE_RA_TOTAL + TOE_RA_TOTAL_INITIAL + L_R_Toe + TOE_RL_INITIAL +\\\n",
        "           R_R_Toe + TOE_RR_INITIAL +  cell_id+ Vehicle_Type Drive_+ Engine_+ Cab_+ CabStyle + Engine + RearWheels +\\\n",
        "           SteeringGear + Suspension + Tire + Transmission + Wheel + wheelbase_broadcast + LaneDeparture + MY'\n",
        "\n",
        "modelo = bmb.Model(formula, target, family=\"bernoulli\")\n",
        "modelo.build()\n",
        "modelo.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NuAvspa_s5J"
      },
      "outputs": [],
      "source": [
        "data1 = modelo.fit(draws=2000, tune=1000, chains=4,target_accept=0.95,\n",
        "                    random_seed=123,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIEMfFBl_g-K"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ii1s6OO_47y"
      },
      "outputs": [],
      "source": [
        "ll_pointwise = data1.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaHOW_SrAAcF"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total = ll_pointwise.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat = ll_total.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "849HBcNfADsv"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.plot_priors()"
      ],
      "metadata": {
        "id": "Io0_T2jhmYHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6pS9F8JuF46"
      },
      "source": [
        "## VIF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for columns in df_train[object_cols]:\n",
        "  print(df_train[columns].value_counts())"
      ],
      "metadata": {
        "id": "WC0KyKEqZ0Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rAbSiMAuIuo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def process_and_analyze_features(df_input: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Realiza o pré-processamento de features numéricas e categóricas,\n",
        "    calcula o VIF (Variance Inflation Factor) para identificar multicolinearidade\n",
        "    e exibe um heatmap de correlação.\n",
        "\n",
        "    Args:\n",
        "        df_input (pd.DataFrame): O DataFrame de entrada contendo as features\n",
        "                                  e a coluna 'Warranty'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Uma tupla contendo:\n",
        "               - X_processed (pd.DataFrame): O DataFrame de features processadas.\n",
        "               - vif_data (pd.DataFrame): O DataFrame com os resultados do VIF.\n",
        "    \"\"\"\n",
        "    # Separar features (X) e target (y)\n",
        "    X = df_input.drop('Warranty', axis=1)\n",
        "    y = df_input['Warranty']\n",
        "\n",
        "    # --- Identificar features numéricas e categóricas (usando suas listas) ---\n",
        "    numerical_features_to_scale = X.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_features = X.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "    # --- Filtrar X para ter apenas as features que você listou ---\n",
        "    all_expected_features = numerical_features_to_scale + categorical_features\n",
        "    X = X[all_expected_features]\n",
        "\n",
        "    # --- 2. Pré-processar Features Numéricas (Standard Scaling) ---\n",
        "    scaler = StandardScaler()\n",
        "    X_numerical_scaled_array = scaler.fit_transform(X[numerical_features_to_scale])\n",
        "\n",
        "    # Converta o array de volta para DataFrame usando os nomes corretos\n",
        "    X_numerical_processed = pd.DataFrame(X_numerical_scaled_array, columns=numerical_features_to_scale, index=X.index)\n",
        "\n",
        "    # --- 3. Pré-processar Features Categóricas (pd.get_dummies) ---\n",
        "    X_categorical_processed = pd.get_dummies(X[categorical_features], columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # --- 4. Combinar as features processadas (numéricas escaladas e categóricas dummy) ---\n",
        "    X_processed = pd.concat([X_numerical_processed, X_categorical_processed], axis=1)\n",
        "\n",
        "    # --- VERIFICAÇÕES DE SEGURANÇA E CONVERSÃO DE TIPO (CRÍTICO) ---\n",
        "\n",
        "    # 1. Converte todas as colunas para tipo numérico, coercing erros para NaN\n",
        "    X_processed = X_processed.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # 2. **NOVO PASSO CRÍTICO**: Força o DataFrame inteiro para float64\n",
        "    # Isso garante que todas as colunas tenham um dtype numérico adequado para operações NumPy\n",
        "    X_processed = X_processed.astype(np.float64)\n",
        "\n",
        "    # 3. Verifica e lida com NaN (se algum foi introduzido por 'coerce' ou por problemas do scaler)\n",
        "    if X_processed.isnull().sum().sum() > 0:\n",
        "        print(\"AVISO: NaNs encontrados nos dados processados após conversão. Preenchendo com a média da coluna.\")\n",
        "        # Preencher NaNs com a média da coluna\n",
        "        X_processed = X_processed.fillna(X_processed.mean())\n",
        "        # Se uma coluna inteira for NaN (e.g., se to_numeric resultou em NaN para toda a coluna),\n",
        "        # a média também será NaN. Preenche com 0 nesses casos.\n",
        "        X_processed = X_processed.fillna(0)\n",
        "\n",
        "    # 4. Verifica e lida com Infinitos (se algum foi introduzido pelo scaler)\n",
        "    if np.isinf(X_processed.values).sum() > 0:\n",
        "        print(\"AVISO: Infs encontrados nos dados processados. Substituindo por NaN e depois preenchendo com 0.\")\n",
        "        X_processed = X_processed.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    #print(f\"Dtypes dos dados processados DEPOIS da limpeza:\\n{X_processed.dtypes}\\n\")\n",
        "\n",
        "    # --- 5. Calcular o VIF para cada feature ---\n",
        "    # Adiciona uma constante (intercepto) ao DataFrame para o cálculo do VIF\n",
        "    X_processed_with_const = sm.add_constant(X_processed, has_constant='add')\n",
        "\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"feature\"] = X_processed_with_const.columns\n",
        "    # Não precisa mais do .astype(np.float64) aqui, pois já foi feito acima\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X_processed_with_const.values, i)\n",
        "                       for i in range(X_processed_with_const.shape[1])]\n",
        "\n",
        "    # Remover a linha da constante do VIF\n",
        "    vif_data = vif_data[vif_data['feature'] != 'const']\n",
        "\n",
        "    # Classificar para facilitar a visualização\n",
        "    vif_data = vif_data.sort_values(by=\"VIF\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nResultados do VIF:\")\n",
        "    print(vif_data)\n",
        "\n",
        "    # --- 6. Interpretação (Exemplo) ---\n",
        "    print(\"\\n--- Interpretação ---\")\n",
        "    high_vif_features = vif_data[vif_data['VIF'] >= 3]\n",
        "    if not high_vif_features.empty:\n",
        "        print(\"\\nFeatures com alta multicolinearidade (VIF >= 3):\")\n",
        "        print(high_vif_features)\n",
        "        print(\"\\nConsidere remover ou combinar essas features para melhorar a estabilidade do modelo.\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma feature com alta multicolinearidade (VIF >= 3) encontrada.\")\n",
        "\n",
        "    # --- 7. Outros métodos visuais (complementares) ---\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    sns.heatmap(X_processed.corr(), cmap='coolwarm', linewidths=.1, linecolor='lightgray', square=True)\n",
        "    plt.title('Matriz de Correlação das Features Processadas')\n",
        "    plt.show()\n",
        "\n",
        "    return X_processed, vif_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSqhHiPCA2_P"
      },
      "outputs": [],
      "source": [
        "check_multi = process_and_analyze_features(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "v9u3uq29PqLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wijvWxKEDdzP"
      },
      "outputs": [],
      "source": [
        "filtered_columns_for_vif = [\n",
        "    'Warranty', # variável target\n",
        "    # Vamos listar apenas as preditoras para o X.\n",
        "\n",
        "    # Features Numéricas\n",
        "    'Rear_Thrust_Angle_Final_Value',\n",
        "    'RIDE_HEIGHT_FA_DIFF',\n",
        "    'RIDE_HEIGHT_RA_DIFF',\n",
        "    'RIDE_HEIGHT_RL',\n",
        "    'RIDE_HEIGHT_RR',\n",
        "    'Steering_Wheel_Angle_Final_Value',\n",
        "    'Steering_Wheel_Angle_Preset_Value',\n",
        "    'TOE_RA_TOTAL', # Mantida, mas será crucial observar seu VIF novamente\n",
        "\n",
        "    # Features Categóricas (serão expandidas por pd.get_dummies)\n",
        "    'cell_id',\n",
        "    'CabStyle',\n",
        "    'Engine',\n",
        "    'RearWheels',\n",
        "    'SteeringGear',\n",
        "    'Suspension', # Mantida, pd.get_dummies(drop_first=True) deve resolver o VIF alto de seus dummies\n",
        "    'Tire',\n",
        "    'Transmission',\n",
        "    'Wheel',\n",
        "    'LaneDeparture',\n",
        "    'Vehicle_Type', # Mantida (efeito aleatório no modelo, mas tratada como fixa para VIF)\n",
        "    'MY'            # Mantida (efeito aleatório no modelo, mas tratada como fixa para VIF)\n",
        "]\n",
        "\n",
        "X_for_vif = df_train[filtered_columns_for_vif].copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_for_vif.columns"
      ],
      "metadata": {
        "id": "lfkyOAT0p3fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaIu4ZcuBAAq"
      },
      "outputs": [],
      "source": [
        "check_multi = process_and_analyze_features(X_for_vif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jJvLkPYB3DX"
      },
      "outputs": [],
      "source": [
        "X_for_vif.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFRYl7YKB3GB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O4dECx4X66W"
      },
      "source": [
        "## Base sem multicolineriedade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_for_vif.columns"
      ],
      "metadata": {
        "id": "hAHXH-POqlz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_vif = target[['Warranty', 'Rear_Thrust_Angle_Final_Value', 'RIDE_HEIGHT_FA_DIFF',\n",
        "       'RIDE_HEIGHT_RA_DIFF', 'RIDE_HEIGHT_RL', 'RIDE_HEIGHT_RR',\n",
        "       'Steering_Wheel_Angle_Final_Value', 'Steering_Wheel_Angle_Preset_Value',\n",
        "       'TOE_RA_TOTAL', 'cell_id', 'CabStyle', 'Engine', 'RearWheels',\n",
        "       'SteeringGear', 'Suspension', 'Tire', 'Transmission', 'Wheel',\n",
        "       'LaneDeparture', 'Vehicle_Type', 'MY']]"
      ],
      "metadata": {
        "id": "Zh9foJxDqpjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8hcEocuwX7f"
      },
      "outputs": [],
      "source": [
        "formula_vif2 = 'Warranty ~ Rear_Thrust_Angle_Final_Value +  RIDE_HEIGHT_FA_DIFF +\\\n",
        "        RIDE_HEIGHT_RA_DIFF +  RIDE_HEIGHT_RL +  RIDE_HEIGHT_RR +\\\n",
        "        Steering_Wheel_Angle_Final_Value +  Steering_Wheel_Angle_Preset_Value +\\\n",
        "        TOE_RA_TOTAL +  cell_id +  CabStyle +  Engine +  RearWheels +\\\n",
        "        SteeringGear +  Suspension +  Tire +  Transmission +  Wheel +\\\n",
        "        LaneDeparture +  Vehicle_Type +  MY'\n",
        "\n",
        "modelo_sem_vif2 = bmb.Model(formula_vif2, target_vif, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPHw6A8ri16e"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7tPZ40Jj2-x"
      },
      "outputs": [],
      "source": [
        "modelo_sem_vif2.build()\n",
        "modelo_sem_vif2.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u7rmQYxj3Bk"
      },
      "outputs": [],
      "source": [
        "data1_sem_vif2 = modelo_sem_vif2.fit(draws=2000, tune=1000, chains=4,target_accept=0.95,\n",
        "                    random_seed=123,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Bs937xvSj3KD"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_sem_vif2, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZK6C6vYhse0N"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_sem_vif2 = data1_sem_vif2.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcgFD_1use55"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhHQOyf6se8S"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_sem_vif2 = ll_pointwise_sem_vif2.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_sem_vif2 = ll_total_sem_vif2.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_sem_vif2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym4lBiwqse-2"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_sem_vif2)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZo216cPPCLj"
      },
      "source": [
        "## Multinivel VT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjvBo_IV0F8L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5O9eJqaPFls"
      },
      "outputs": [],
      "source": [
        "formula_multi = 'Warranty ~ TOE_RA_TOTAL + RIDE_HEIGHT_RA_DIFF + ' \\\n",
        "          'LaneDeparture + SteeringGear + Wheel + ' \\\n",
        "          '(1|Vehicle_Type)'\n",
        "\n",
        "modelo_multi = bmb.Model(formula_multi, target, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znSi1gk7PFlt"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXBWm_5PFlt"
      },
      "outputs": [],
      "source": [
        "modelo_multi.build()\n",
        "modelo_multi.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jpwD4DaPFlt"
      },
      "outputs": [],
      "source": [
        "data1_multi = modelo_multi.fit(draws=2000, tune=1000, chains=4,target_accept=0.99,\n",
        "                    random_seed=123,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-JTG6JYlPFlu"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_multi, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88canbMnPFlu"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_multi = data1_multi.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jykwi8ubPFlu"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctMbPidJPFlv"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_multi = ll_pointwise_multi.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_multi = ll_total_multi.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_multi))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPAyUmwtPFlv"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_multi)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zsuK3sENDBj2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oq3BWRDhDEKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5o0jDGFDHDu"
      },
      "source": [
        "## Multinivel Pit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXn-wy9GDHDv"
      },
      "outputs": [],
      "source": [
        "formula_multi_2 = 'Warranty ~ TOE_RA_TOTAL + RIDE_HEIGHT_RA_DIFF + ' \\\n",
        "          'LaneDeparture + SteeringGear + Wheel + ' \\\n",
        "          '(1|cell_id)'\n",
        "\n",
        "modelo_multi_2 = bmb.Model(formula_multi_2, target, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poXzAoN5DHDv"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GgsWzBkDHDv"
      },
      "outputs": [],
      "source": [
        "modelo_multi_2.build()\n",
        "modelo_multi_2.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLEEoH2sDHDw"
      },
      "outputs": [],
      "source": [
        "data1_multi_2 = modelo_multi_2.fit(draws=2000, tune=1000, chains=4,target_accept=0.999,\n",
        "                    random_seed=123, max_treedepth=25,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hAzpUpfyDHDw"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_multi_2, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kAd2ynYDHDw"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_multi_2 = data1_multi_2.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKdu_XK_DHDw"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcDsIlyyDHDx"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_multi_2 = ll_pointwise_multi_2.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_multi_2 = ll_total_multi_2.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_multi_2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIEVsnzpDHDx"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_multi_2)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multinivel SG"
      ],
      "metadata": {
        "id": "_iYJqBAxGTgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5MoOXfmGcAu"
      },
      "outputs": [],
      "source": [
        "formula_multi_sg = 'Warranty ~ RIDE_HEIGHT_RL + Steering_Wheel_Angle_Final_Value + RIDE_HEIGHT_RA_DIFF + \\\n",
        "                  RIDE_HEIGHT_RR + Wheel + (1|SteeringGear)'\n",
        "\n",
        "modelo_multi_sg = bmb.Model(formula_multi_sg, target, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onLjJSj1GcAv"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv762NfvGcAv"
      },
      "outputs": [],
      "source": [
        "modelo_multi_sg.build()\n",
        "modelo_multi_sg.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kal9qpiJGcAv"
      },
      "outputs": [],
      "source": [
        "data1_multi_sg = modelo_multi_sg.fit(draws=2000, tune=1000, chains=4,target_accept=0.999,\n",
        "                    random_seed=123, max_treedepth=25,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OvI6VMdQGcAw"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_multi_sg, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYDQIuOgGcAw"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_multi_sg = data1_multi_sg.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oHCPQu9GcAw"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmQ7wqPmGcAw"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_multi_sg = ll_pointwise_multi_sg.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_multi_sg = ll_total_multi_sg.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_multi_sg))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDh8rImBGcAx"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_multi_sg)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYXJEKHltWYg"
      },
      "source": [
        "## Multinivel Wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlKQCS_JtWYh"
      },
      "outputs": [],
      "source": [
        "formula_wheel = 'Warranty ~ TOE_RA_TOTAL + RIDE_HEIGHT_RA_DIFF + SteeringGear + (1|Wheel)'\n",
        "\n",
        "modelo_wheel = bmb.Model(formula_wheel, target, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwwpOEIntWYh"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RckgxduhtWYh"
      },
      "outputs": [],
      "source": [
        "modelo_wheel.build()\n",
        "modelo_wheel.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p8fXfnitWYi"
      },
      "outputs": [],
      "source": [
        "data1_wheel = modelo_wheel.fit(draws=2000, tune=1000, chains=4,target_accept=0.95,\n",
        "                    random_seed=123,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3mZThjpEtWYi"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_wheel, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYzmoPdNtWYj"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_wheel = data1_wheel.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PyZLHKqtWYj"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGERi54-tWYj"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_wheel = ll_pointwise_wheel.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_wheel = ll_total_wheel.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_wheel))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L791CNLbtWYj"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_wheel)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multinivel Wheel 2"
      ],
      "metadata": {
        "id": "GZ--5TtggT2l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReN8uLJ6galT"
      },
      "outputs": [],
      "source": [
        "formula_wheel = 'Warranty ~ TOE_RA_TOTAL + (1|Wheel)'\n",
        "\n",
        "modelo_wheel = bmb.Model(formula_wheel, target, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOthVEvJgalT"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ztc-21MgalT"
      },
      "outputs": [],
      "source": [
        "modelo_wheel.build()\n",
        "modelo_wheel.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_Uo7HgLgalU"
      },
      "outputs": [],
      "source": [
        "data1_wheel = modelo_wheel.fit(draws=2000, tune=1000, chains=4,target_accept=0.999,\n",
        "                    random_seed=123,max_treedepth=25,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Fwm-jqDtgalU"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_wheel, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCEuqY2ggalU"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_wheel = data1_wheel.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqqEI70OgalU"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftq2FhQlgalV"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_wheel = ll_pointwise_wheel.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_wheel = ll_total_wheel.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_wheel))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5n9_7F5galV"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_wheel)\n",
        "print(f\"LOO: {loo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classico Toe e Wheel"
      ],
      "metadata": {
        "id": "Y-ts01Cpo1V2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l33q1ltVo_r2"
      },
      "outputs": [],
      "source": [
        "formula_wheel_toe = 'Warranty ~ TOE_RA_TOTAL + Wheel'\n",
        "\n",
        "modelo_wheel_toe = bmb.Model(formula_wheel_toe, target, family=\"bernoulli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJGeCaTzo_r2"
      },
      "outputs": [],
      "source": [
        "#print(modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJCgE_9co_r3"
      },
      "outputs": [],
      "source": [
        "modelo_wheel_toe.build()\n",
        "modelo_wheel_toe.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3c1nqEVo_r3"
      },
      "outputs": [],
      "source": [
        "data1_wheel_toe = modelo_wheel_toe.fit(draws=2000, tune=1000, chains=4,target_accept=0.95,\n",
        "                    random_seed=123,\n",
        "                    idata_kwargs={\"log_likelihood\": True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SzP7LwMxo_r4"
      },
      "outputs": [],
      "source": [
        "pm.summary(data1_wheel_toe, hdi_prob=0.95, round_to=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH6EViNko_r4"
      },
      "outputs": [],
      "source": [
        "ll_pointwise_wheel_toe = data1_wheel_toe.log_likelihood[\"Warranty\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olppHm5wo_r4"
      },
      "outputs": [],
      "source": [
        "#z.plot_trace(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ebHrZ_do_r4"
      },
      "outputs": [],
      "source": [
        "# 2. somar sobre cada observação → log-likelihood total por amostra\n",
        "    # Usar '__obs__' em vez de 'observation'\n",
        "ll_total_wheel_toe = ll_pointwise_wheel_toe.sum(dim=\"__obs__\")         # dims: (\"chain\", \"draw\")\n",
        "\n",
        "    # 3. Se quiser empilhar cadeias e amostras em um só eixo:\n",
        "ll_total_flat_wheel_toe = ll_total_wheel_toe.stack(sample=(\"chain\", \"draw\")).values\n",
        "print(np.mean(ll_total_flat_wheel_toe))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe5PktjQo_r5"
      },
      "outputs": [],
      "source": [
        "loo = az.loo(data1_wheel_toe)\n",
        "print(f\"LOO: {loo}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sMsu1qu-pIHN",
        "0lP1wKp3pOXJ"
      ],
      "authorship_tag": "ABX9TyPz0rRqJGu9+Z+c1r0AD+Il",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}